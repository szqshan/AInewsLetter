#!/usr/bin/env python3
"""
çˆ¬è™«æ€§èƒ½å¯¹æ¯”è„šæœ¬
"""

import asyncio
import sys
import time
from pathlib import Path
import json

# æ·»åŠ  src åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).resolve().parents[1]))  # æŒ‡å‘ src ç›®å½•

from newsletter_system.crawler.newsletter_crawler import NewsletterCrawler, CrawlerConfig


async def benchmark_basic_crawler():
    """æµ‹è¯•åŸºç¡€çˆ¬è™«æ€§èƒ½"""
    print("ğŸ” æµ‹è¯•åŸºç¡€çˆ¬è™«...")
    
    start_time = time.time()
    
    try:
        config = CrawlerConfig(
            output_dir="test_basic",
            max_concurrent_articles=3,
            max_concurrent_images=8,
            batch_size=5,
            enable_resume=False
        )
        async with NewsletterCrawler(config) as crawler:
            # åªè·å–å‰5ç¯‡æ–‡ç« è¿›è¡Œæµ‹è¯•
            articles_metadata = await crawler.get_all_articles_metadata()
            test_articles = articles_metadata[:5]

            # ä¸€æ¬¡æ‰¹é‡å¤„ç†
            results = await crawler.process_article_batch(test_articles)
            processed_count = len([r for r in results if r is not None])

            elapsed = time.time() - start_time

            return {
                'name': 'åŸºç¡€çˆ¬è™«',
                'processed_articles': processed_count,
                'total_time': elapsed,
                'avg_time_per_article': elapsed / processed_count if processed_count > 0 else 0
            }
    except Exception as e:
        print(f"åŸºç¡€çˆ¬è™«æµ‹è¯•å¤±è´¥: {e}")
        return None


async def benchmark_optimized_crawler():
    """å ä½ï¼šä¼˜åŒ–çˆ¬è™«ï¼ˆå½“å‰æœªå®ç°ï¼‰ï¼Œè¿”å› Noneã€‚"""
    print("ğŸš€ æµ‹è¯•ä¼˜åŒ–çˆ¬è™«ï¼ˆå ä½ï¼Œæœªå®ç°ï¼‰...")
    return None


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š çˆ¬è™«æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•åŸºç¡€çˆ¬è™«
    basic_result = await benchmark_basic_crawler()
    
    print("\n" + "=" * 50)
    
    # æµ‹è¯•ä¼˜åŒ–çˆ¬è™«
    optimized_result = await benchmark_optimized_crawler()
    
    print("\n" + "=" * 50)
    print("ğŸ“ˆ æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    print("=" * 50)
    
    if basic_result:
        print(f"ğŸ” {basic_result['name']}:")
        print(f"   - å¤„ç†æ–‡ç« æ•°: {basic_result['processed_articles']}")
        print(f"   - æ€»è€—æ—¶: {basic_result['total_time']:.2f}ç§’")
        print(f"   - å¹³å‡æ¯ç¯‡: {basic_result['avg_time_per_article']:.2f}ç§’")
        print()
    
    if optimized_result:
        print(f"ğŸš€ {optimized_result['name']}:")
        print(f"   - å¤„ç†æ–‡ç« æ•°: {optimized_result['processed_articles']}")
        print(f"   - æ€»è€—æ—¶: {optimized_result['total_time']:.2f}ç§’")
        print(f"   - å¹³å‡æ¯ç¯‡: {optimized_result['avg_time_per_article']:.2f}ç§’")
        print()
    
    if basic_result and optimized_result:
        if optimized_result['total_time'] > 0:
            speedup = basic_result['total_time'] / optimized_result['total_time']
            print(f"âš¡ æ€§èƒ½æå‡: {speedup:.2f}x")
            
            efficiency_improvement = (basic_result['avg_time_per_article'] - optimized_result['avg_time_per_article']) / basic_result['avg_time_per_article'] * 100
            print(f"ğŸ“Š æ•ˆç‡æå‡: {efficiency_improvement:.1f}%")
    
    print("\nğŸ’¡ å»ºè®®:")
    print("- è‹¥é‡é™æµ/éªŒè¯ç ï¼Œå»ºè®®ä½¿ç”¨ run_anti_detect.pyï¼ˆåçˆ¬å¢å¼ºç‰ˆï¼‰")
    print("- å¯ä»¥é€šè¿‡è°ƒæ•´å¹¶å‘ä¸å»¶è¿Ÿå‚æ•°è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½")
    print("- å¯ç”¨æ–­ç‚¹ç»­ä¼ åŠŸèƒ½å¯ä»¥é¿å…é‡å¤å·¥ä½œ")


if __name__ == "__main__":
    asyncio.run(main())