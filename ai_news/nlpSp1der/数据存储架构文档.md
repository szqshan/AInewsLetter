# Newsletter爬虫数据存储架构文档

## 一、数据存储结构

### 1.1 文件系统组织架构

系统采用分层目录结构存储爬取的数据：

```
crawled_data/
├── articles/                           # 文章独立存储目录
│   └── {article_id}_{safe_title}/     # 每篇文章独立文件夹
│       ├── content.md                 # 清洁的Markdown内容
│       ├── metadata.json              # 文章元数据（不含正文）
│       └── images/                    # 本地化图片
│           ├── cover.jpg              # 封面图
│           └── img_*.jpg              # 内容图片
├── data/                              # 全局聚合数据
│   ├── articles_metadata.json        # 原始API响应数据
│   ├── processed_articles.json       # 完整处理后数据（含内容）
│   ├── recommendation_data.json      # 机器学习用精简数据
│   └── crawl_stats.json              # 爬取统计信息
└── images/                           # 全局图片目录（旧版兼容）
```

### 1.2 核心数据模型

#### 文章元数据结构（metadata.json）
```json
{
  "id": 169787925,                    // 文章唯一ID
  "title": "Top AI Papers of the Week",
  "subtitle": "The Top AI Papers...",
  "post_date": "2025-08-03T14:55:49.289Z",
  "canonical_url": "https://...",
  "slug": "top-ai-papers-week",
  "type": "newsletter",               // newsletter|tutorial|paper
  "audience": "everyone",              // everyone|only_paid
  "wordcount": 1948,
  "reactions": {"❤": 29},
  "postTags": [
    {"name": "AI", "slug": "ai", "id": "uuid"}
  ],
  "cover_image_info": {
    "path": "relative/path/to/image",
    "hash": "sha256_hash",            // 图片完整性校验
    "size": 242270                    // 字节大小
  },
  "local_images": [                   // 内容图片列表
    {
      "original_url": "https://...",
      "local_path": "articles/.../images/img_0.jpg",
      "hash": "sha256_hash",
      "size": 71676
    }
  ],
  "content_hash": "sha256_of_markdown",  // 内容完整性校验
  "processed_date": "2025-08-06T15:48:50.708994"
}
```

#### 推荐引擎数据结构（recommendation_data.json）
```json
{
  "id": 169787925,
  "title": "用于相似度匹配的标题",
  "subtitle": "副标题（TF-IDF权重2x）",
  "description": "描述文本",
  "postTags": [{"name": "AI", "slug": "ai", "id": "uuid"}],
  "reactions": {"❤": 29},             // 互动指标
  "wordcount": 1948,                  // 内容长度
  "post_date": "ISO_timestamp",       // 时间特征
  "type": "newsletter",                // 内容分类
  "audience": "everyone"               // 访问级别
}
```

## 二、数据存储流程

### 2.1 ETL数据处理管道

#### **提取阶段（Extract）**
```python
# 数据源API调用
API_ENDPOINT = "https://nlp.elvissaravia.com/api/v1/archive"
PARAMS = {
    "sort": "new",
    "offset": 0,      # 分页偏移
    "limit": 12       # 每批12篇文章
}

# 速率限制配置
RATE_LIMITS = {
    "api_delay": 1,        # API请求间隔（秒）
    "article_delay": 2     # 文章处理间隔（秒）
}
```

#### **转换阶段（Transform）**
1. **内容提取**：使用Playwright渲染JavaScript，CSS选择器优先级链：
   ```python
   content_selectors = [
       '.markup',                    # 优先：干净内容
       '.body.markup',               # 更具体的内容选择器
       'article .markup',            # 限定article范围
       'article .body',              # article内替代选择器
       '.single-post-container',     # 后备选择器
       '.post-content',
       '.entry-content',
       # ... 更多后备方案
   ]
   ```

2. **图片处理流程**：
   - 下载所有图片（封面+内容图片）
   - 生成SHA256哈希值确保完整性
   - 替换HTML中的图片URL为相对路径
   - 优化图片格式和大小

3. **内容转换**：
   - HTML → Markdown（使用markdownify库）
   - 清理UI元素（分享按钮、订阅提示等）
   - 保留语义化标记

#### **加载阶段（Load）**
三层数据存储策略：
1. **原始数据层**：`articles_metadata.json` - API原始响应
2. **处理数据层**：`processed_articles.json` - 完整处理后数据
3. **应用数据层**：`recommendation_data.json` - ML模型用数据

### 2.2 并发处理架构

#### **资源管理**
```python
# 并发控制配置
CONCURRENCY_CONFIG = {
    "max_concurrent_articles": 5,     # 文章并发处理数
    "max_concurrent_images": 20,      # 图片并发下载数
    "browser_pool_size": 3,           # Playwright页面实例池
    "connection_pool": {
        "total": 100,                  # 总连接数
        "per_host": 30                 # 每主机连接数
    }
}
```

#### **错误处理与恢复机制**
```python
# 重试策略
RETRY_STRATEGY = {
    "max_retries": 3,
    "backoff_factor": 2,              # 指数退避：2^attempt
    "timeout": 30,                     # 请求超时（秒）
    "resume_enabled": True             # 断点续传
}

# 错误处理优先级
ERROR_HANDLING = [
    "exponential_backoff",             # 指数退避重试
    "progress_checkpoint",             # 进度检查点
    "rate_limit_detection",            # 速率限制检测
    "graceful_degradation"             # 优雅降级
]
```

## 三、数据上传流程（OSS集成）

### 3.1 MinIO对象存储架构

#### **存储桶组织策略**
```
newsletter-articles-{source_id}/
├── articles/
│   └── {article_slug}/
│       ├── content.md                 # 公开访问的Markdown
│       ├── metadata.json              # 更新后的元数据
│       └── images/
│           ├── cover.jpg
│           └── img_*.jpg
└── global/
    ├── articles_metadata.json
    ├── processed_articles.json
    └── recommendation_data.json
```

#### **URL转换流程**
```python
# 原始本地路径
original: "![](images/img_0.jpg)"

# 转换为OSS公开URL
transformed: "![](http://localhost:9000/newsletter-articles-nlp/articles/slug/images/img_0.jpg)"
```

### 3.2 上传工作流

```python
# 上传流程步骤
upload_workflow = [
    {
        "step": 1,
        "action": "create_bucket",
        "endpoint": "POST /buckets",
        "params": {"name": "newsletter-articles-{source}"}
    },
    {
        "step": 2,
        "action": "set_public_access",
        "endpoint": "PUT /buckets/{name}/make-public"
    },
    {
        "step": 3,
        "action": "batch_upload_images",
        "endpoint": "POST /objects/{bucket}/upload",
        "batch_size": 50
    },
    {
        "step": 4,
        "action": "update_content_urls",
        "process": "replace_local_with_public_urls"
    },
    {
        "step": 5,
        "action": "upload_processed_content",
        "files": ["content.md", "metadata.json"]
    }
]
```

### 3.3 API集成接口

#### **Newsletter源API**
```http
GET https://nlp.elvissaravia.com/api/v1/archive
Parameters:
  - sort: new|old|popular
  - offset: 分页偏移量
  - limit: 每页数量（最大12）
  
Response:
{
  "articles": [...],
  "total": 180,
  "hasMore": boolean
}
```

#### **MinIO OSS API**
```http
# 创建存储桶
POST http://localhost:9011/api/v1/buckets
Body: {"name": "bucket-name"}

# 设置公开访问
PUT http://localhost:9011/api/v1/buckets/{name}/make-public

# 上传文件
POST http://localhost:9011/api/v1/objects/{bucket}/upload
Body: multipart/form-data

# 公开访问URL格式
GET http://localhost:9000/{bucket}/{object-path}
```

## 四、性能与扩展性

### 4.1 当前运行指标
- **处理规模**：180篇文章成功处理
- **图片数量**：473张图片下载并本地化
- **处理时间**：约470秒（平均2.6秒/文章）
- **失败率**：0%（最新运行）
- **存储占用**：约500MB（含图片）

### 4.2 性能瓶颈分析
1. **浏览器实例限制**：单实例限制文章处理吞吐量
2. **顺序图片下载**：文章内图片顺序处理（全局批量并发）
3. **文件存储限制**：JSON文件限制查询能力
4. **网络延迟**：API速率限制和网络传输

### 4.3 扩展性设计

#### **MVP系统集成准备**
```yaml
database:
  type: PostgreSQL
  features:
    - JSONB字段存储灵活元数据
    - 文章全文索引
    - 用户行为追踪表

search:
  type: Elasticsearch
  features:
    - 384维密集向量嵌入
    - BM25全文搜索
    - 聚合分析

storage:
  type: MinIO
  structure:
    - images/covers/     # 封面图
    - images/content/    # 内容图
    - articles/markdown/ # 文章内容

api:
  type: FastAPI
  features:
    - 用户行为追踪
    - 推荐反馈收集
    - 缓存策略
```

#### **扩展点设计**
1. **任务队列系统**：基于数据库的任务队列表
2. **分布式爬取**：多节点并行处理支持
3. **增量更新**：基于时间戳的增量爬取
4. **数据版本控制**：内容变更追踪
5. **监控告警**：处理状态实时监控

## 五、关键实现细节

### 5.1 数据完整性保证
- **SHA256哈希**：所有图片和内容生成哈希值
- **事务性写入**：先写临时文件，成功后重命名
- **增量保存**：每处理完一篇立即保存，防止数据丢失

### 5.2 错误恢复能力
- **断点续传**：记录已处理文章ID，支持中断恢复
- **优雅降级**：单个图片失败不影响整体处理
- **详细日志**：完整的错误堆栈和处理状态记录

### 5.3 配置驱动设计
所有关键参数可通过`config.json`配置：
```json
{
  "crawler": {
    "request_delay": 2,
    "max_retries": 3,
    "timeout": 30,
    "concurrent_articles": 5,
    "concurrent_images": 20
  },
  "storage": {
    "output_dir": "crawled_data",
    "enable_resume": true
  },
  "oss": {
    "endpoint": "http://localhost:9000",
    "bucket_prefix": "newsletter-articles"
  }
}
```

## 六、使用建议

### 6.1 适用场景
- Newsletter内容聚合平台
- 技术文章推荐系统
- 内容分析和趋势研究
- 知识库构建

### 6.2 注意事项
- 遵守目标网站robots.txt和使用条款
- 合理设置爬取频率，避免对源站造成压力
- 定期清理旧数据，优化存储空间
- 监控爬取质量，及时调整选择器

### 6.3 后续优化方向
1. 实现数据库持久化存储
2. 添加内容去重机制
3. 支持多源数据聚合
4. 实现实时推荐更新
5. 添加内容质量评分

---

*本文档描述了Newsletter爬虫系统的完整数据架构，为系统集成和二次开发提供技术参考。*