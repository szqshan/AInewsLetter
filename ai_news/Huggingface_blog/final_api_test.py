#!/usr/bin/env python3
"""
æœ€ç»ˆAPIæµ‹è¯•å’Œåšå®¢æ•°æ®æå–æ–¹æ¡ˆ
"""

import json
import requests
from urllib.parse import urljoin, urlparse
import time
import re

class HuggingFaceBlogAPI:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json',
            'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
        })
        self.base_url = "https://huggingface.co"
        
    def test_posts_api_with_different_params(self):
        """æµ‹è¯•Posts APIçš„ä¸åŒå‚æ•°ç»„åˆæ¥è·å–æ›´å¤šåšå®¢ç›¸å…³å†…å®¹"""
        print("ğŸ”¬ æµ‹è¯•ä¸åŒå‚æ•°ç»„åˆæ¥è·å–åšå®¢å†…å®¹...")
        
        api_url = f"{self.base_url}/api/posts"
        
        # é«˜çº§å‚æ•°æµ‹è¯•
        advanced_params = [
            # æµ‹è¯•æ›´å¤§çš„limitå€¼
            {'limit': 50},
            {'limit': 100},
            
            # æµ‹è¯•åˆ†é¡µ
            {'page': 0, 'limit': 50},
            {'page': 1, 'limit': 50},
            {'page': 2, 'limit': 50},
            
            # æµ‹è¯•offset
            {'offset': 0, 'limit': 50},
            {'offset': 50, 'limit': 50},
            {'offset': 100, 'limit': 50},
            
            # æµ‹è¯•æ—¥æœŸèŒƒå›´
            {'since': '2025-08-01', 'limit': 50},
            {'since': '2025-07-01', 'limit': 50},
            {'since': '2025-06-01', 'limit': 50},
            
            # æµ‹è¯•trending
            {'sort': 'trending', 'limit': 50},
            
            # æµ‹è¯•åšå®¢ç›¸å…³è¿‡æ»¤å™¨
            {'type': 'blog', 'limit': 50},
            {'category': 'blog', 'limit': 50},
            {'filter': 'blog', 'limit': 50},
            {'tag': 'blog', 'limit': 50},
        ]
        
        all_blog_posts = {}  # ç”¨slugä½œä¸ºkeyå»é‡
        
        for params in advanced_params:
            print(f"   æµ‹è¯•å‚æ•°: {params}")
            
            try:
                response = self.session.get(api_url, params=params, timeout=15)
                
                if response.status_code == 200:
                    data = response.json()
                    posts = data.get('socialPosts', [])
                    
                    blog_posts_found = 0
                    
                    for post in posts:
                        content = post.get('rawContent', '').lower()
                        
                        # æ›´ä¸¥æ ¼çš„åšå®¢æ£€æµ‹
                        blog_indicators = [
                            'huggingface.co/blog/' in content,
                            'âœ… new article' in content,
                            'blog post' in content,
                            'new blog' in content,
                            '/blog/' in content and 'article' in content
                        ]
                        
                        if any(blog_indicators):
                            slug = post.get('slug')
                            if slug not in all_blog_posts:
                                all_blog_posts[slug] = post
                                blog_posts_found += 1
                    
                    print(f"      æ‰¾åˆ° {blog_posts_found} ä¸ªæ–°çš„åšå®¢posts")
                    
                else:
                    print(f"      å¤±è´¥: {response.status_code}")
                    
            except Exception as e:
                print(f"      é”™è¯¯: {e}")
            
            time.sleep(0.5)
        
        print(f"\n   æ€»å…±å‘ç° {len(all_blog_posts)} ä¸ªå”¯ä¸€çš„åšå®¢ç›¸å…³posts")
        return list(all_blog_posts.values())
    
    def extract_blog_links_from_posts(self, posts):
        """ä»postsä¸­æå–æ‰€æœ‰åšå®¢é“¾æ¥"""
        print(f"\nğŸ“ ä» {len(posts)} ä¸ªpostsä¸­æå–åšå®¢é“¾æ¥...")
        
        blog_links = []
        
        for post in posts:
            content = post.get('rawContent', '')
            
            # æå–åšå®¢é“¾æ¥çš„æ­£åˆ™è¡¨è¾¾å¼
            patterns = [
                r'https://huggingface\.co/blog/[^\s\)\]"\'>]+',
                r'huggingface\.co/blog/[^\s\)\]"\'>]+',
                r'/blog/[^\s\)\]"\'>]+(?=\s|$|[\)\]"\'>])'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    # æ¸…ç†å’Œæ ‡å‡†åŒ–é“¾æ¥
                    if not match.startswith('http'):
                        match = 'https://huggingface.co' + (match if match.startswith('/') else '/' + match)
                    
                    # ç§»é™¤æœ«å°¾çš„æ ‡ç‚¹ç¬¦å·
                    match = re.sub(r'[,\.\)\]"\'>]+$', '', match)
                    
                    if match not in blog_links:
                        blog_links.append(match)
                        
                        # æå–é¢å¤–ä¿¡æ¯
                        blog_info = {
                            'url': match,
                            'found_in_post': post.get('slug'),
                            'post_author': post.get('author', {}).get('name'),
                            'post_date': post.get('publishedAt'),
                            'post_content_preview': content[:200] + '...'
                        }
                        
                        # åˆ†æé“¾æ¥ç»“æ„
                        parsed = urlparse(match)
                        path_parts = parsed.path.strip('/').split('/')
                        if len(path_parts) >= 2 and path_parts[0] == 'blog':
                            if len(path_parts) == 2:
                                # /blog/zh æ ¼å¼
                                blog_info['type'] = 'language_homepage'
                                blog_info['language'] = path_parts[1]
                            elif len(path_parts) >= 3:
                                # /blog/author/title æ ¼å¼
                                blog_info['type'] = 'article'
                                blog_info['author'] = path_parts[1]
                                blog_info['article_slug'] = path_parts[2]
                        
                        print(f"   å‘ç°åšå®¢é“¾æ¥: {match}")
                        if 'type' in blog_info:
                            print(f"      ç±»å‹: {blog_info['type']}")
                            if blog_info['type'] == 'article':
                                print(f"      ä½œè€…: {blog_info.get('author')}")
                                print(f"      æ–‡ç« : {blog_info.get('article_slug')}")
        
        return blog_links
    
    def test_blog_page_direct_access(self):
        """ç›´æ¥æµ‹è¯•åšå®¢é¡µé¢çš„è®¿é—®"""
        print(f"\nğŸŒ ç›´æ¥æµ‹è¯•åšå®¢é¡µé¢è®¿é—®...")
        
        blog_urls = [
            'https://huggingface.co/blog',
            'https://huggingface.co/blog/zh',
            'https://huggingface.co/blog/en',
            'https://huggingface.co/blog/latest',
            'https://huggingface.co/blog/all',
        ]
        
        results = []
        
        for url in blog_urls:
            print(f"   æµ‹è¯•: {url}")
            
            try:
                response = self.session.get(url, timeout=10)
                
                result = {
                    'url': url,
                    'status_code': response.status_code,
                    'content_type': response.headers.get('content-type', ''),
                    'size': len(response.content)
                }
                
                if response.status_code == 200:
                    print(f"      âœ… æˆåŠŸè®¿é—®")
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†é¡µä¿¡æ¯
                    content = response.text
                    if '?p=' in content or 'page=' in content:
                        result['has_pagination'] = True
                        print(f"      ğŸ“„ åŒ…å«åˆ†é¡µ")
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«JSONæ•°æ®
                    json_pattern = r'<script[^>]*>.*?window\.__[A-Z_]+__\s*=\s*(\{.*?\});'
                    json_matches = re.findall(json_pattern, content, re.DOTALL)
                    if json_matches:
                        result['embedded_json_count'] = len(json_matches)
                        print(f"      ğŸ“Š åŒ…å« {len(json_matches)} ä¸ªå†…åµŒJSONå¯¹è±¡")
                        
                        # å°è¯•è§£æç¬¬ä¸€ä¸ªJSON
                        try:
                            first_json = json.loads(json_matches[0])
                            if isinstance(first_json, dict):
                                result['json_keys'] = list(first_json.keys())[:10]
                                print(f"      ğŸ”‘ JSONé”®: {result['json_keys']}")
                        except:
                            pass
                    
                else:
                    print(f"      âŒ å¤±è´¥: {response.status_code}")
                
                results.append(result)
                
            except Exception as e:
                print(f"      âš ï¸  é”™è¯¯: {e}")
                results.append({
                    'url': url,
                    'error': str(e)
                })
            
            time.sleep(0.5)
        
        return results
    
    def generate_final_recommendations(self):
        """ç”Ÿæˆæœ€ç»ˆçš„æ•°æ®è·å–å»ºè®®"""
        print("\n" + "="*80)
        print("ğŸ¯ HUGGING FACE åšå®¢æ•°æ®è·å–æœ€ç»ˆåˆ†ææŠ¥å‘Š")
        print("="*80)
        
        # 1. æµ‹è¯•æ›´å¤špostså‚æ•°
        print("\n1ï¸âƒ£ æ‰©å±•Posts APIæµ‹è¯•")
        blog_posts = self.test_posts_api_with_different_params()
        
        # 2. æå–åšå®¢é“¾æ¥
        print("\n2ï¸âƒ£ åšå®¢é“¾æ¥æå–")
        if blog_posts:
            blog_links = self.extract_blog_links_from_posts(blog_posts)
        else:
            blog_links = []
        
        # 3. ç›´æ¥æµ‹è¯•åšå®¢é¡µé¢
        print("\n3ï¸âƒ£ ç›´æ¥åšå®¢é¡µé¢æµ‹è¯•")
        blog_page_results = self.test_blog_page_direct_access()
        
        # 4. ç”Ÿæˆæœ€ç»ˆå»ºè®®
        print("\n4ï¸âƒ£ æœ€ç»ˆå»ºè®®")
        
        successful_blog_pages = [r for r in blog_page_results if r.get('status_code') == 200]
        has_embedded_json = any(r.get('embedded_json_count', 0) > 0 for r in successful_blog_pages)
        
        print(f"\nğŸ“Š å‘ç°çš„æ•°æ®æº:")
        print(f"   Posts APIä¸­çš„åšå®¢ç›¸å…³å†…å®¹: {len(blog_posts)} ä¸ª")
        print(f"   æå–çš„åšå®¢é“¾æ¥: {len(blog_links)} ä¸ª")
        print(f"   å¯è®¿é—®çš„åšå®¢é¡µé¢: {len(successful_blog_pages)} ä¸ª")
        print(f"   åŒ…å«å†…åµŒJSONçš„é¡µé¢: {sum(1 for r in successful_blog_pages if r.get('embedded_json_count', 0) > 0)} ä¸ª")
        
        # æ¨èæœ€ä½³æ–¹æ¡ˆ
        recommendations = []
        
        if len(blog_posts) > 0:
            recommendations.append({
                'priority': 1,
                'method': 'Posts API + åšå®¢é“¾æ¥æå–',
                'description': f'ä½¿ç”¨ /api/posts è·å–ç¤¾äº¤åŠ¨æ€ï¼Œä»ä¸­æå– {len(blog_links)} ä¸ªåšå®¢é“¾æ¥',
                'api_endpoint': 'https://huggingface.co/api/posts',
                'parameters': ['limit=50', 'since=2025-06-01', 'sort=trending'],
                'pros': ['åŒ…å«å®Œæ•´çš„åšå®¢æ–‡ç« é“¾æ¥', 'å¯ä»¥è·å–æ–‡ç« å‘å¸ƒæ—¶é—´å’Œä½œè€…ä¿¡æ¯', 'JSONæ ¼å¼ä¾¿äºå¤„ç†'],
                'cons': ['éœ€è¦ä»åŠ¨æ€ä¸­è¿‡æ»¤åšå®¢å†…å®¹', 'å¯èƒ½æ— æ³•è·å–å†å²æ–‡ç« '],
                'implementation': 'requests + æ­£åˆ™è¡¨è¾¾å¼æå–åšå®¢é“¾æ¥'
            })
        
        if has_embedded_json:
            recommendations.append({
                'priority': 2,
                'method': 'åšå®¢é¡µé¢å†…åµŒJSONæ•°æ®',
                'description': 'ç›´æ¥è®¿é—®åšå®¢é¡µé¢ï¼Œè§£æå†…åµŒçš„JSONæ•°æ®',
                'api_endpoint': 'https://huggingface.co/blog/zh',
                'parameters': ['åˆ†é¡µå‚æ•°: ?p=0,1,2...'],
                'pros': ['å¯èƒ½åŒ…å«å®Œæ•´çš„åšå®¢åˆ—è¡¨', 'æ•°æ®ç»“æ„åŒ–', 'æ”¯æŒåˆ†é¡µ'],
                'cons': ['éœ€è¦è§£æHTMLä¸­çš„JavaScript', 'å¯èƒ½éœ€è¦å¤„ç†åçˆ¬è™«æœºåˆ¶'],
                'implementation': 'requests + BeautifulSoup + JSONè§£æ'
            })
        
        recommendations.append({
            'priority': 3,
            'method': 'ä¼ ç»ŸHTMLè§£æ',
            'description': 'ç›´æ¥è§£æåšå®¢é¡µé¢çš„HTMLç»“æ„',
            'api_endpoint': 'https://huggingface.co/blog/zh',
            'parameters': ['åˆ†é¡µå‚æ•°: ?p=0,1,2...'],
            'pros': ['æœ€ç¨³å®šå¯é ', 'ä¸ä¾èµ–APIç¨³å®šæ€§', 'å¯ä»¥è·å–æ‰€æœ‰å…¬å¼€ä¿¡æ¯'],
            'cons': ['éœ€è¦å¤„ç†å¤æ‚çš„HTMLç»“æ„', 'æ€§èƒ½ç›¸å¯¹è¾ƒä½', 'å¯èƒ½å—é¡µé¢æ”¹ç‰ˆå½±å“'],
            'implementation': 'requests + BeautifulSoup + CSSé€‰æ‹©å™¨'
        })
        
        print(f"\nğŸ¥‡ æ¨èçš„æ•°æ®è·å–æ–¹æ¡ˆ (æŒ‰ä¼˜å…ˆçº§æ’åº):")
        
        for i, rec in enumerate(recommendations, 1):
            print(f"\n   {i}. {rec['method']} (ä¼˜å…ˆçº§: {rec['priority']})")
            print(f"      æè¿°: {rec['description']}")
            print(f"      ç«¯ç‚¹: {rec['api_endpoint']}")
            print(f"      å‚æ•°: {', '.join(rec['parameters'])}")
            print(f"      ä¼˜ç‚¹: {', '.join(rec['pros'])}")
            print(f"      ç¼ºç‚¹: {', '.join(rec['cons'])}")
            print(f"      å®ç°: {rec['implementation']}")
        
        # ä¿å­˜å®Œæ•´æŠ¥å‘Š
        final_report = {
            'analysis_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'summary': {
                'blog_posts_from_api': len(blog_posts),
                'extracted_blog_links': len(blog_links),
                'accessible_blog_pages': len(successful_blog_pages),
                'pages_with_embedded_json': sum(1 for r in successful_blog_pages if r.get('embedded_json_count', 0) > 0)
            },
            'blog_posts': blog_posts,
            'blog_links': blog_links,
            'blog_page_results': blog_page_results,
            'recommendations': recommendations
        }
        
        with open('/home/shan/Huggingface_blog/final_analysis_report.json', 'w', encoding='utf-8') as f:
            json.dump(final_report, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: /home/shan/Huggingface_blog/final_analysis_report.json")
        
        return final_report

def main():
    analyzer = HuggingFaceBlogAPI()
    analyzer.generate_final_recommendations()

if __name__ == "__main__":
    main()