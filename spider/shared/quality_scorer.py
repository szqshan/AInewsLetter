#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è´¨é‡è¯„ä¼°æ¨¡å—
ç”¨äºè¯„ä¼°è®ºæ–‡ã€æ–°é—»ã€å·¥å…·ç­‰å†…å®¹çš„è´¨é‡
"""

import re
import math
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging

logger = logging.getLogger(__name__)

class QualityScorer:
    """
    å†…å®¹è´¨é‡è¯„ä¼°å™¨
    """
    
    def __init__(self):
        # é¡¶çº§ä¼šè®®å’ŒæœŸåˆŠ
        self.top_venues = {
            "NIPS": 10, "NeurIPS": 10, "ICML": 10, "ICLR": 10,
            "ACL": 9, "EMNLP": 9, "NAACL": 8, "COLING": 7,
            "CVPR": 10, "ICCV": 10, "ECCV": 9, "AAAI": 8,
            "IJCAI": 8, "KDD": 8, "WWW": 7, "SIGIR": 7,
            "Nature": 10, "Science": 10, "Cell": 9,
            "JMLR": 9, "PAMI": 8, "AIJ": 7
        }
        
        # çŸ¥åæœºæ„å’Œä½œè€…æƒé‡
        self.institution_weights = {
            "OpenAI": 10, "Google": 9, "Microsoft": 9, "Facebook": 9,
            "Stanford": 10, "MIT": 10, "CMU": 10, "Berkeley": 9,
            "Harvard": 9, "Oxford": 8, "Cambridge": 8,
            "æ¸…å": 8, "åŒ—å¤§": 8, "ä¸­ç§‘é™¢": 7
        }
        
        # å…³é”®è¯æƒé‡
        self.keyword_weights = {
            "GPT": 3, "BERT": 2, "Transformer": 2, "LLM": 3,
            "ChatGPT": 3, "Claude": 2, "Gemini": 2,
            "æ·±åº¦å­¦ä¹ ": 2, "æœºå™¨å­¦ä¹ ": 1, "äººå·¥æ™ºèƒ½": 1,
            "neural network": 1, "deep learning": 2, "machine learning": 1
        }
    
    def score_paper(self, paper: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯„ä¼°è®ºæ–‡è´¨é‡
        
        Args:
            paper: è®ºæ–‡ä¿¡æ¯å­—å…¸
        
        Returns:
            åŒ…å«è´¨é‡åˆ†æ•°çš„å­—å…¸
        """
        scores = {
            "citation_score": 0,
            "venue_score": 0,
            "author_score": 0,
            "recency_score": 0,
            "keyword_score": 0,
            "total_score": 0
        }
        
        # å¼•ç”¨æ•°è¯„åˆ†
        citation_count = paper.get("citation_count", 0)
        scores["citation_score"] = self._calculate_citation_score(citation_count)
        
        # ä¼šè®®/æœŸåˆŠè¯„åˆ†
        venue = paper.get("venue", "")
        scores["venue_score"] = self._calculate_venue_score(venue)
        
        # ä½œè€…/æœºæ„è¯„åˆ†
        authors = paper.get("authors", [])
        affiliations = paper.get("affiliations", [])
        scores["author_score"] = self._calculate_author_score(authors, affiliations)
        
        # æ—¶æ•ˆæ€§è¯„åˆ†
        publish_date = paper.get("published", "")
        scores["recency_score"] = self._calculate_recency_score(publish_date)
        
        # å…³é”®è¯è¯„åˆ†
        title = paper.get("title", "")
        abstract = paper.get("summary", "")
        scores["keyword_score"] = self._calculate_keyword_score(title + " " + abstract)
        
        # è®¡ç®—æ€»åˆ†
        weights = {
            "citation_score": 0.3,
            "venue_score": 0.25,
            "author_score": 0.2,
            "recency_score": 0.15,
            "keyword_score": 0.1
        }
        
        total = sum(scores[key] * weights[key] for key in weights)
        scores["total_score"] = round(total, 2)
        
        # æ·»åŠ è´¨é‡ç­‰çº§
        scores["quality_level"] = self._get_quality_level(scores["total_score"])
        
        return scores
    
    def score_news(self, news: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯„ä¼°æ–°é—»è´¨é‡
        
        Args:
            news: æ–°é—»ä¿¡æ¯å­—å…¸
        
        Returns:
            åŒ…å«è´¨é‡åˆ†æ•°çš„å­—å…¸
        """
        scores = {
            "source_score": 0,
            "content_score": 0,
            "engagement_score": 0,
            "recency_score": 0,
            "total_score": 0
        }
        
        # æ¥æºå¯é æ€§è¯„åˆ†
        source = news.get("source", "")
        scores["source_score"] = self._calculate_source_score(source)
        
        # å†…å®¹è´¨é‡è¯„åˆ†
        title = news.get("title", "")
        content = news.get("content", "")
        scores["content_score"] = self._calculate_content_score(title, content)
        
        # å‚ä¸åº¦è¯„åˆ†ï¼ˆç‚¹èµã€è¯„è®ºç­‰ï¼‰
        engagement = news.get("engagement", {})
        scores["engagement_score"] = self._calculate_engagement_score(engagement)
        
        # æ—¶æ•ˆæ€§è¯„åˆ†
        publish_date = news.get("published", "")
        scores["recency_score"] = self._calculate_recency_score(publish_date)
        
        # è®¡ç®—æ€»åˆ†
        weights = {
            "source_score": 0.3,
            "content_score": 0.4,
            "engagement_score": 0.2,
            "recency_score": 0.1
        }
        
        total = sum(scores[key] * weights[key] for key in weights)
        scores["total_score"] = round(total, 2)
        scores["quality_level"] = self._get_quality_level(scores["total_score"])
        
        return scores
    
    def score_tool(self, tool: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯„ä¼°AIå·¥å…·è´¨é‡
        
        Args:
            tool: å·¥å…·ä¿¡æ¯å­—å…¸
        
        Returns:
            åŒ…å«è´¨é‡åˆ†æ•°çš„å­—å…¸
        """
        scores = {
            "popularity_score": 0,
            "functionality_score": 0,
            "maintenance_score": 0,
            "documentation_score": 0,
            "total_score": 0
        }
        
        # å—æ¬¢è¿ç¨‹åº¦è¯„åˆ†ï¼ˆGitHubæ˜Ÿæ•°ã€ä¸‹è½½é‡ç­‰ï¼‰
        popularity = tool.get("popularity", {})
        scores["popularity_score"] = self._calculate_popularity_score(popularity)
        
        # åŠŸèƒ½æ€§è¯„åˆ†
        description = tool.get("description", "")
        features = tool.get("features", [])
        scores["functionality_score"] = self._calculate_functionality_score(description, features)
        
        # ç»´æŠ¤çŠ¶æ€è¯„åˆ†
        last_update = tool.get("last_update", "")
        scores["maintenance_score"] = self._calculate_maintenance_score(last_update)
        
        # æ–‡æ¡£è´¨é‡è¯„åˆ†
        has_docs = tool.get("has_documentation", False)
        readme_quality = tool.get("readme_quality", 0)
        scores["documentation_score"] = self._calculate_documentation_score(has_docs, readme_quality)
        
        # è®¡ç®—æ€»åˆ†
        weights = {
            "popularity_score": 0.3,
            "functionality_score": 0.3,
            "maintenance_score": 0.25,
            "documentation_score": 0.15
        }
        
        total = sum(scores[key] * weights[key] for key in weights)
        scores["total_score"] = round(total, 2)
        scores["quality_level"] = self._get_quality_level(scores["total_score"])
        
        return scores
    
    def _calculate_citation_score(self, citation_count: int) -> float:
        """è®¡ç®—å¼•ç”¨æ•°è¯„åˆ†"""
        if citation_count <= 0:
            return 0
        # ä½¿ç”¨å¯¹æ•°å‡½æ•°ï¼Œé¿å…æå€¼å½±å“
        return min(10, math.log10(citation_count + 1) * 2)
    
    def _calculate_venue_score(self, venue: str) -> float:
        """è®¡ç®—ä¼šè®®/æœŸåˆŠè¯„åˆ†"""
        venue_upper = venue.upper()
        for v, score in self.top_venues.items():
            if v.upper() in venue_upper:
                return score
        return 3  # é»˜è®¤åˆ†æ•°
    
    def _calculate_author_score(self, authors: List[str], affiliations: List[str]) -> float:
        """è®¡ç®—ä½œè€…/æœºæ„è¯„åˆ†"""
        max_score = 0
        
        # æ£€æŸ¥æœºæ„
        for affiliation in affiliations:
            for inst, score in self.institution_weights.items():
                if inst.lower() in affiliation.lower():
                    max_score = max(max_score, score)
        
        return min(10, max_score)
    
    def _calculate_recency_score(self, publish_date: str) -> float:
        """è®¡ç®—æ—¶æ•ˆæ€§è¯„åˆ†"""
        try:
            if not publish_date:
                return 5
            
            # Try to parse date
            if isinstance(publish_date, str):
                from dateutil import parser
                pub_date = parser.parse(publish_date)
            else:
                pub_date = publish_date
            
            days_ago = (datetime.now() - pub_date).days
            
            if days_ago <= 7:
                return 10  # ä¸€å‘¨å†…
            elif days_ago <= 30:
                return 8   # ä¸€æœˆå†…
            elif days_ago <= 90:
                return 6   # ä¸‰æœˆå†…
            elif days_ago <= 365:
                return 4   # ä¸€å¹´å†…
            else:
                return 2   # è¶…è¿‡ä¸€å¹´
        except:
            return 5  # è§£æå¤±è´¥ï¼Œç»™é»˜è®¤åˆ†
    
    def _calculate_keyword_score(self, text: str) -> float:
        """è®¡ç®—å…³é”®è¯è¯„åˆ†"""
        text_lower = text.lower()
        score = 0
        
        for keyword, weight in self.keyword_weights.items():
            if keyword.lower() in text_lower:
                score += weight
        
        return min(10, score)
    
    def _calculate_source_score(self, source: str) -> float:
        """è®¡ç®—æ–°é—»æ¥æºè¯„åˆ†"""
        reliable_sources = {
            "openai": 10, "google": 9, "microsoft": 9,
            "arxiv": 10, "nature": 10, "science": 10,
            "mit": 9, "stanford": 9, "berkeley": 8,
            "æœºå™¨ä¹‹å¿ƒ": 7, "é‡å­ä½": 7, "aiç§‘æŠ€å¤§æœ¬è¥": 6
        }
        
        source_lower = source.lower()
        for src, score in reliable_sources.items():
            if src in source_lower:
                return score
        
        return 5  # é»˜è®¤åˆ†æ•°
    
    def _calculate_content_score(self, title: str, content: str) -> float:
        """è®¡ç®—å†…å®¹è´¨é‡è¯„åˆ†"""
        score = 5  # åŸºç¡€åˆ†
        
        # æ ‡é¢˜é•¿åº¦åˆç†æ€§
        if 10 <= len(title) <= 100:
            score += 1
        
        # å†…å®¹é•¿åº¦
        if len(content) > 500:
            score += 2
        elif len(content) > 200:
            score += 1
        
        # åŒ…å«æŠ€æœ¯å…³é”®è¯
        tech_keywords = ["AI", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç®—æ³•", "æ¨¡å‹", "æ•°æ®"]
        keyword_count = sum(1 for kw in tech_keywords if kw.lower() in (title + content).lower())
        score += min(2, keyword_count * 0.5)
        
        return min(10, score)
    
    def _calculate_engagement_score(self, engagement: Dict) -> float:
        """è®¡ç®—å‚ä¸åº¦è¯„åˆ†"""
        likes = engagement.get("likes", 0)
        comments = engagement.get("comments", 0)
        shares = engagement.get("shares", 0)
        
        total_engagement = likes + comments * 2 + shares * 3
        
        if total_engagement >= 1000:
            return 10
        elif total_engagement >= 500:
            return 8
        elif total_engagement >= 100:
            return 6
        elif total_engagement >= 10:
            return 4
        else:
            return 2
    
    def _calculate_popularity_score(self, popularity: Dict) -> float:
        """è®¡ç®—å·¥å…·å—æ¬¢è¿ç¨‹åº¦è¯„åˆ†"""
        stars = popularity.get("github_stars", 0)
        downloads = popularity.get("downloads", 0)
        forks = popularity.get("forks", 0)
        
        score = 0
        
        # GitHubæ˜Ÿæ•°è¯„åˆ†
        if stars >= 10000:
            score += 4
        elif stars >= 1000:
            score += 3
        elif stars >= 100:
            score += 2
        elif stars >= 10:
            score += 1
        
        # ä¸‹è½½é‡è¯„åˆ†
        if downloads >= 100000:
            score += 3
        elif downloads >= 10000:
            score += 2
        elif downloads >= 1000:
            score += 1
        
        # Forkæ•°è¯„åˆ†
        if forks >= 1000:
            score += 3
        elif forks >= 100:
            score += 2
        elif forks >= 10:
            score += 1
        
        return min(10, score)
    
    def _calculate_functionality_score(self, description: str, features: List[str]) -> float:
        """è®¡ç®—åŠŸèƒ½æ€§è¯„åˆ†"""
        score = 5  # åŸºç¡€åˆ†
        
        # æè¿°è´¨é‡
        if len(description) > 100:
            score += 2
        elif len(description) > 50:
            score += 1
        
        # åŠŸèƒ½æ•°é‡
        score += min(3, len(features) * 0.5)
        
        return min(10, score)
    
    def _calculate_maintenance_score(self, last_update: str) -> float:
        """è®¡ç®—ç»´æŠ¤çŠ¶æ€è¯„åˆ†"""
        try:
            if not last_update:
                return 3
            
            from dateutil import parser
            update_date = parser.parse(last_update)
            days_ago = (datetime.now() - update_date).days
            
            if days_ago <= 30:
                return 10  # ä¸€æœˆå†…æ›´æ–°
            elif days_ago <= 90:
                return 8   # ä¸‰æœˆå†…æ›´æ–°
            elif days_ago <= 180:
                return 6   # åŠå¹´å†…æ›´æ–°
            elif days_ago <= 365:
                return 4   # ä¸€å¹´å†…æ›´æ–°
            else:
                return 2   # è¶…è¿‡ä¸€å¹´æœªæ›´æ–°
        except:
            return 5
    
    def _calculate_documentation_score(self, has_docs: bool, readme_quality: int) -> float:
        """è®¡ç®—æ–‡æ¡£è´¨é‡è¯„åˆ†"""
        score = 0
        
        if has_docs:
            score += 5
        
        score += min(5, readme_quality)
        
        return min(10, score)
    
    def _get_quality_level(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°è·å–è´¨é‡ç­‰çº§"""
        if score >= 8.5:
            return "ä¼˜ç§€"
        elif score >= 7.0:
            return "è‰¯å¥½"
        elif score >= 5.5:
            return "ä¸€èˆ¬"
        elif score >= 4.0:
            return "è¾ƒå·®"
        else:
            return "å¾ˆå·®"

if __name__ == "__main__":
    # æµ‹è¯•è´¨é‡è¯„ä¼°å™¨
    scorer = QualityScorer()
    
    # æµ‹è¯•è®ºæ–‡è¯„åˆ†
    test_paper = {
        "title": "GPT-4: A Large-Scale Language Model",
        "summary": "This paper presents GPT-4, a large language model...",
        "citation_count": 1500,
        "venue": "NIPS 2023",
        "authors": ["John Doe", "Jane Smith"],
        "affiliations": ["OpenAI", "Stanford University"],
        "published": "2023-12-01"
    }
    
    paper_scores = scorer.score_paper(test_paper)
    print("ğŸ“Š è®ºæ–‡è´¨é‡è¯„åˆ†:")
    for key, value in paper_scores.items():
        print(f"  {key}: {value}")
    
    print("\nâœ… è´¨é‡è¯„ä¼°å™¨æµ‹è¯•å®Œæˆ")
