# AIå†…å®¹èšåˆçˆ¬è™«ç³»ç»Ÿ

ä¸€ä¸ªå…¨é¢çš„AIå†…å®¹èšåˆçˆ¬è™«ç³»ç»Ÿï¼Œç”¨äºè‡ªåŠ¨æ”¶é›†ã€åˆ†æå’Œæ•´ç†æ¥è‡ªå„ç§å¹³å°çš„AIç›¸å…³å†…å®¹ï¼ŒåŒ…æ‹¬å­¦æœ¯è®ºæ–‡ã€æ–°é—»èµ„è®¯å’Œå·¥å…·é¡¹ç›®ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

- **å¤šå¹³å°æ”¯æŒ**: æ”¯æŒarXivã€Google Scholarã€Hugging Faceã€GitHub Trendingç­‰å¤šä¸ªå¹³å°
- **æ™ºèƒ½è´¨é‡è¯„ä¼°**: åŸºäºå¤šç»´åº¦æŒ‡æ ‡è‡ªåŠ¨è¯„ä¼°å†…å®¹è´¨é‡
- **ç»“æ„åŒ–å­˜å‚¨**: è‡ªåŠ¨ç”ŸæˆJSONå’ŒMarkdownæ ¼å¼çš„ç»“æ„åŒ–æ•°æ®
- **æ¨¡å—åŒ–è®¾è®¡**: æ˜“äºæ‰©å±•å’Œç»´æŠ¤çš„æ¨¡å—åŒ–æ¶æ„
- **å¼‚æ­¥å¤„ç†**: æ”¯æŒå¹¶å‘çˆ¬å–ï¼Œæé«˜æ•ˆç‡
- **æ™ºèƒ½å»é‡**: è‡ªåŠ¨è¯†åˆ«å’Œè¿‡æ»¤é‡å¤å†…å®¹
- **å®šæ—¶ä»»åŠ¡**: æ”¯æŒå®šæ—¶è‡ªåŠ¨è¿è¡Œ

## ğŸ“ é¡¹ç›®ç»“æ„

```
spider/
â”œâ”€â”€ academic_papers/          # å­¦æœ¯è®ºæ–‡çˆ¬è™«
â”‚   â”œâ”€â”€ arxiv/               # arXivè®ºæ–‡
â”‚   â”œâ”€â”€ google_scholar/      # Google Scholar
â”‚   â”œâ”€â”€ papers_with_code/    # Papers with Code
â”‚   â”œâ”€â”€ semantic_scholar/    # Semantic Scholar
â”‚   â”œâ”€â”€ acl_anthology/       # ACL Anthology
â”‚   â””â”€â”€ conference_papers/   # ä¼šè®®è®ºæ–‡
â”œâ”€â”€ ai_news/                 # AIæ–°é—»çˆ¬è™«
â”‚   â”œâ”€â”€ huggingface_daily/   # Hugging Faceæ¯æ—¥è®ºæ–‡
â”‚   â”œâ”€â”€ reddit_ai/           # Reddit AIç¤¾åŒº
â”‚   â”œâ”€â”€ towards_datascience/ # Towards Data Science
â”‚   â”œâ”€â”€ openai_blog/         # OpenAIåšå®¢
â”‚   â”œâ”€â”€ google_ai_blog/      # Google AIåšå®¢
â”‚   â””â”€â”€ chinese_media/       # ä¸­æ–‡AIåª’ä½“
â”œâ”€â”€ ai_tools/                # AIå·¥å…·çˆ¬è™«
â”‚   â”œâ”€â”€ github_trending/     # GitHub Trending
â”‚   â”œâ”€â”€ product_hunt/        # Product Hunt
â”‚   â”œâ”€â”€ awesome_lists/       # Awesomeåˆ—è¡¨
â”‚   â””â”€â”€ tool_directories/    # å·¥å…·ç›®å½•
â”œâ”€â”€ shared/                  # å…±äº«æ¨¡å—
â”‚   â”œâ”€â”€ config.py           # å…¨å±€é…ç½®
â”‚   â”œâ”€â”€ utils.py            # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ quality_scorer.py   # è´¨é‡è¯„ä¼°
â”œâ”€â”€ data/                    # æ•°æ®å­˜å‚¨
â”‚   â”œâ”€â”€ raw/                # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ processed/          # å¤„ç†åæ•°æ®
â”‚   â””â”€â”€ exports/            # å¯¼å‡ºæ•°æ®
â”œâ”€â”€ main.py                 # ä¸»æ§åˆ¶è„šæœ¬
â”œâ”€â”€ requirements.txt        # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md              # é¡¹ç›®è¯´æ˜
```

## ğŸ› ï¸ å®‰è£…å’Œé…ç½®

### 1. ç¯å¢ƒè¦æ±‚

- Python 3.8+
- pip æˆ– conda

### 2. å®‰è£…ä¾èµ–

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd spider

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 3. é…ç½®è®¾ç½®

ç¼–è¾‘ `shared/config.py` æ–‡ä»¶ï¼Œæ ¹æ®éœ€è¦è°ƒæ•´é…ç½®å‚æ•°ï¼š

```python
# ç¤ºä¾‹é…ç½®
ARXIV_CONFIG = {
    'max_results': 50,
    'categories': ['cs.AI', 'cs.LG', 'cs.CL'],
    'search_terms': ['artificial intelligence', 'machine learning']
}
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. è¿è¡Œæ‰€æœ‰çˆ¬è™«

```bash
python main.py
```

### 2. è¿è¡Œç‰¹å®šç±»å‹çš„çˆ¬è™«

```bash
# åªè¿è¡Œå­¦æœ¯è®ºæ–‡çˆ¬è™«
python main.py --type academic

# åªè¿è¡ŒAIæ–°é—»çˆ¬è™«
python main.py --type news

# åªè¿è¡ŒAIå·¥å…·çˆ¬è™«
python main.py --type tools
```

### 3. è¿è¡Œå•ä¸ªçˆ¬è™«

```bash
# è¿è¡ŒarXivçˆ¬è™«
python academic_papers/arxiv/spider.py

# è¿è¡ŒGitHub Trendingçˆ¬è™«
python ai_tools/github_trending/spider.py
```

## ğŸ“Š æ•°æ®è¾“å‡º

### è¾“å‡ºæ ¼å¼

æ¯ä¸ªçˆ¬è™«éƒ½ä¼šç”Ÿæˆä¸¤ç§æ ¼å¼çš„è¾“å‡ºï¼š

1. **JSONæ ¼å¼**: ç»“æ„åŒ–æ•°æ®ï¼Œä¾¿äºç¨‹åºå¤„ç†
2. **Markdownæ ¼å¼**: äººç±»å¯è¯»çš„æŠ¥å‘Šæ ¼å¼

### è¾“å‡ºç¤ºä¾‹

#### JSONæ ¼å¼
```json
{
  "title": "Attention Is All You Need",
  "authors": "Vaswani et al.",
  "abstract": "The dominant sequence transduction models...",
  "url": "https://arxiv.org/abs/1706.03762",
  "citations": 50000,
  "quality_score": {
    "total_score": 95.5,
    "citation_score": 100,
    "venue_score": 90,
    "recency_score": 85
  },
  "scraped_at": "2024-01-15T10:30:00"
}
```

#### Markdownæ ¼å¼
```markdown
# arXiv AI Papers - 2024-01-15

## 1. Attention Is All You Need

**ä½œè€…**: Vaswani et al.
**å¼•ç”¨æ•°**: 50,000
**è´¨é‡è¯„åˆ†**: 95.5/100

**æ‘˜è¦**: The dominant sequence transduction models...

**é“¾æ¥**: https://arxiv.org/abs/1706.03762
```

## ğŸ”§ è´¨é‡è¯„ä¼°ç³»ç»Ÿ

ç³»ç»Ÿå†…ç½®æ™ºèƒ½è´¨é‡è¯„ä¼°åŠŸèƒ½ï¼ŒåŸºäºå¤šä¸ªç»´åº¦å¯¹å†…å®¹è¿›è¡Œè¯„åˆ†ï¼š

### å­¦æœ¯è®ºæ–‡è¯„ä¼°
- **å¼•ç”¨æ•°é‡** (30%): è®ºæ–‡çš„å½±å“åŠ›æŒ‡æ ‡
- **å‘è¡¨venue** (25%): ä¼šè®®/æœŸåˆŠçš„å£°èª‰
- **ä½œè€…/æœºæ„** (20%): ä½œè€…å’Œæœºæ„çš„æƒå¨æ€§
- **æ—¶æ•ˆæ€§** (15%): è®ºæ–‡çš„æ–°é¢–ç¨‹åº¦
- **å…³é”®è¯åŒ¹é…** (10%): ä¸AIé¢†åŸŸçš„ç›¸å…³æ€§

### AIæ–°é—»è¯„ä¼°
- **æ¥æºå¯é æ€§** (30%): æ–°é—»æ¥æºçš„æƒå¨æ€§
- **å†…å®¹è´¨é‡** (25%): å†…å®¹çš„æ·±åº¦å’Œå‡†ç¡®æ€§
- **æ—¶æ•ˆæ€§** (20%): æ–°é—»çš„æ–°é²œç¨‹åº¦
- **å‚ä¸åº¦** (15%): ç”¨æˆ·äº’åŠ¨æŒ‡æ ‡
- **å…³é”®è¯åŒ¹é…** (10%): ä¸AIé¢†åŸŸçš„ç›¸å…³æ€§

### AIå·¥å…·è¯„ä¼°
- **å—æ¬¢è¿ç¨‹åº¦** (25%): GitHub starsã€ä¸‹è½½é‡ç­‰
- **æ´»è·ƒåº¦** (25%): æ›´æ–°é¢‘ç‡ã€æäº¤æ´»åŠ¨
- **åŠŸèƒ½æ€§** (20%): å·¥å…·çš„å®ç”¨æ€§å’Œå®Œæ•´æ€§
- **ç»´æŠ¤çŠ¶æ€** (15%): é¡¹ç›®çš„ç»´æŠ¤æƒ…å†µ
- **æ–‡æ¡£è´¨é‡** (15%): æ–‡æ¡£çš„å®Œæ•´æ€§å’Œæ¸…æ™°åº¦

## ğŸ”„ å®šæ—¶ä»»åŠ¡

å¯ä»¥ä½¿ç”¨ç³»ç»Ÿçš„å®šæ—¶ä»»åŠ¡åŠŸèƒ½è‡ªåŠ¨è¿è¡Œçˆ¬è™«ï¼š

```python
# ç¤ºä¾‹ï¼šæ¯å¤©è¿è¡Œä¸€æ¬¡
from apscheduler.schedulers.blocking import BlockingScheduler

scheduler = BlockingScheduler()
scheduler.add_job(main, 'cron', hour=9)  # æ¯å¤©9ç‚¹è¿è¡Œ
scheduler.start()
```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

ç³»ç»Ÿæä¾›è¯¦ç»†çš„æ—¥å¿—è®°å½•å’Œç›‘æ§åŠŸèƒ½ï¼š

- **è¿è¡Œæ—¥å¿—**: è®°å½•çˆ¬è™«è¿è¡ŒçŠ¶æ€å’Œé”™è¯¯ä¿¡æ¯
- **æ€§èƒ½ç›‘æ§**: ç›‘æ§çˆ¬å–é€Ÿåº¦å’ŒæˆåŠŸç‡
- **æ•°æ®ç»Ÿè®¡**: ç»Ÿè®¡çˆ¬å–çš„æ•°æ®é‡å’Œè´¨é‡åˆ†å¸ƒ

## ğŸ›¡ï¸ åçˆ¬è™«ç­–ç•¥

ç³»ç»Ÿå†…ç½®å¤šç§åçˆ¬è™«ç­–ç•¥ï¼š

- **è¯·æ±‚é—´éš”**: æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¿å…è¢«å°IP
- **User-Agentè½®æ¢**: æ¨¡æ‹Ÿä¸åŒæµè§ˆå™¨è®¿é—®
- **ä»£ç†æ”¯æŒ**: æ”¯æŒä»£ç†æ± è½®æ¢
- **é‡è¯•æœºåˆ¶**: è‡ªåŠ¨é‡è¯•å¤±è´¥çš„è¯·æ±‚
- **ç¼“å­˜æœºåˆ¶**: é¿å…é‡å¤è¯·æ±‚ç›¸åŒå†…å®¹

## ğŸ”§ æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„çˆ¬è™«

1. åœ¨ç›¸åº”ç›®å½•ä¸‹åˆ›å»ºæ–°çš„çˆ¬è™«æ–‡ä»¶
2. ç»§æ‰¿åŸºç¡€çˆ¬è™«ç±»
3. å®ç°å¿…è¦çš„æ–¹æ³•
4. åœ¨ä¸»æ§åˆ¶è„šæœ¬ä¸­æ³¨å†Œæ–°çˆ¬è™«

```python
class NewSpider:
    def __init__(self):
        # åˆå§‹åŒ–ä»£ç 
        pass
    
    def crawl(self):
        # çˆ¬å–é€»è¾‘
        pass
    
    def parse(self, response):
        # è§£æé€»è¾‘
        pass
```

### è‡ªå®šä¹‰è´¨é‡è¯„ä¼°

å¯ä»¥åœ¨ `shared/quality_scorer.py` ä¸­æ·»åŠ è‡ªå®šä¹‰çš„è¯„ä¼°é€»è¾‘ï¼š

```python
def custom_score_method(self, item):
    # è‡ªå®šä¹‰è¯„åˆ†é€»è¾‘
    score = 0
    # è®¡ç®—åˆ†æ•°
    return score
```

## ğŸ“ é…ç½®è¯´æ˜

### å…¨å±€é…ç½® (shared/config.py)

```python
# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))

# æ•°æ®å­˜å‚¨è·¯å¾„
DATA_PATHS = {
    'raw': os.path.join(PROJECT_ROOT, 'data', 'raw'),
    'processed': os.path.join(PROJECT_ROOT, 'data', 'processed'),
    'exports': os.path.join(PROJECT_ROOT, 'data', 'exports')
}

# çˆ¬è™«é€šç”¨é…ç½®
CRAWLER_CONFIG = {
    'request_delay': 2,  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
    'max_retries': 3,    # æœ€å¤§é‡è¯•æ¬¡æ•°
    'timeout': 30,       # è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
    'user_agents': [     # User-Agentåˆ—è¡¨
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    ]
}
```

### å¹³å°ç‰¹å®šé…ç½®

æ¯ä¸ªå¹³å°éƒ½æœ‰ç‹¬ç«‹çš„é…ç½®é€‰é¡¹ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ï¼š

```python
# arXivé…ç½®
ARXIV_CONFIG = {
    'base_url': 'http://export.arxiv.org/api/query',
    'max_results': 100,
    'categories': ['cs.AI', 'cs.LG', 'cs.CL', 'cs.CV'],
    'search_terms': [
        'artificial intelligence',
        'machine learning',
        'deep learning',
        'neural network'
    ]
}

# GitHubé…ç½®
GITHUB_CONFIG = {
    'base_url': 'https://api.github.com',
    'token': None,  # GitHub API token (å¯é€‰)
    'languages': ['python', 'javascript', 'typescript'],
    'min_stars': 100,
    'ai_keywords': [
        'artificial intelligence',
        'machine learning',
        'deep learning'
    ]
}
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **è¯·æ±‚è¢«æ‹’ç»**
   - æ£€æŸ¥è¯·æ±‚é—´éš”è®¾ç½®
   - æ›´æ¢User-Agent
   - ä½¿ç”¨ä»£ç†

2. **è§£æå¤±è´¥**
   - æ£€æŸ¥ç½‘ç«™ç»“æ„æ˜¯å¦å˜åŒ–
   - æ›´æ–°è§£æè§„åˆ™
   - æ£€æŸ¥ç¼–ç é—®é¢˜

3. **å†…å­˜ä¸è¶³**
   - å‡å°‘å¹¶å‘æ•°é‡
   - å¢åŠ åˆ†æ‰¹å¤„ç†
   - ä¼˜åŒ–æ•°æ®ç»“æ„

### è°ƒè¯•æ¨¡å¼

å¯ç”¨è°ƒè¯•æ¨¡å¼è·å–è¯¦ç»†æ—¥å¿—ï¼š

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- Email: your-email@example.com
- GitHub: https://github.com/your-username/ai-content-crawler

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºè¿™ä¸ªé¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…å’Œç”¨æˆ·ï¼

---

**æ³¨æ„**: ä½¿ç”¨æœ¬ç³»ç»Ÿæ—¶è¯·éµå®ˆå„å¹³å°çš„robots.txtå’Œä½¿ç”¨æ¡æ¬¾ï¼Œåˆç†æ§åˆ¶çˆ¬å–é¢‘ç‡ï¼Œå°Šé‡ç½‘ç«™èµ„æºã€‚