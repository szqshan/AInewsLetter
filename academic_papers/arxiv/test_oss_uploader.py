#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•OSSä¸Šä¼ å™¨
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from arxiv_system.oss.oss_uploader import ArxivOSSUploader

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä½¿ç”¨OSSä¸Šä¼ å™¨ä¸Šä¼ æ–‡ç« ...")
    
    # åˆå§‹åŒ–ä¸Šä¼ å™¨
    uploader = ArxivOSSUploader(
        base_dir="crawled_data",
        endpoint="http://localhost:9011"
    )
    
    # æ£€æŸ¥æ–‡ç« ç›®å½•
    articles_dir = Path("crawled_data/articles")
    if not articles_dir.exists():
        print("âŒ æ–‡ç« ç›®å½•ä¸å­˜åœ¨:", articles_dir)
        return
    
    article_dirs = [d for d in articles_dir.iterdir() if d.is_dir()]
    print(f"ğŸ“ æ‰¾åˆ° {len(article_dirs)} ä¸ªæ–‡ç« æ–‡ä»¶å¤¹")
    
    if len(article_dirs) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ–‡ç« æ–‡ä»¶å¤¹")
        return
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡ç« ä¿¡æ¯
    print("\nğŸ“‹ æ–‡ç« åˆ—è¡¨ (å‰5ä¸ª):")
    for i, article_dir in enumerate(article_dirs[:5]):
        metadata_file = article_dir / "metadata.json"
        if metadata_file.exists():
            import json
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            title = metadata.get('title', 'æœªçŸ¥æ ‡é¢˜')[:50]
            print(f"  {i+1}. {article_dir.name}: {title}...")
        else:
            print(f"  {i+1}. {article_dir.name}: (æ— å…ƒæ•°æ®)")
    
    # ç¡®è®¤ä¸Šä¼ 
    print(f"\nå‡†å¤‡ä¸Šä¼  {len(article_dirs)} ç¯‡æ–‡ç« åˆ°MinIO...")
    print("è¿™å°†ä¼šåˆ›å»º arxiv-papers å­˜å‚¨æ¡¶å¹¶ä¿æŒæ–‡ä»¶å¤¹ç»“æ„")
    
    # å¼€å§‹ä¸Šä¼ 
    result = await uploader.upload_all(bucket_name="arxiv-papers")
    
    if result['success']:
        print("\nğŸ‰ ä¸Šä¼ å®Œæˆï¼")
        print(f"âœ… æˆåŠŸä¸Šä¼ : {result['uploaded_files']} ä¸ªæ–‡ç« ")
        print(f"â±ï¸  ç”¨æ—¶: {result['elapsed_time_seconds']} ç§’")
        print(f"ğŸª£ å­˜å‚¨æ¡¶: {result['bucket_name']}")
        
        if result.get('sample_urls'):
            print("\nğŸ”— ç¤ºä¾‹URL:")
            for url in result['sample_urls']:
                print(f"  {url}")
    else:
        print(f"\nâŒ ä¸Šä¼ å¤±è´¥: {result.get('error')}")

if __name__ == "__main__":
    asyncio.run(main())

