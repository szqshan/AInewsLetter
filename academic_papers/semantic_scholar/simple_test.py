#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆSemantic Scholarçˆ¬è™«æµ‹è¯•
ç”¨äºè°ƒè¯•å’ŒéªŒè¯åŸºæœ¬åŠŸèƒ½
"""

import asyncio
import aiohttp
import json
import time
from datetime import datetime


async def simple_test():
    """ç®€å•æµ‹è¯•çˆ¬è™«åŠŸèƒ½"""
    print("ğŸ”¬ Semantic Scholar ç®€åŒ–æµ‹è¯•")
    print("=" * 40)
    
    base_url = "https://api.semanticscholar.org/graph/v1"
    
    headers = {
        'User-Agent': 'AI-Newsletter-Test/1.0',
        'Accept': 'application/json'
    }
    
    async with aiohttp.ClientSession(headers=headers) as session:
        # æµ‹è¯•1: ç®€å•æœç´¢
        print("\nğŸ“ æµ‹è¯•1: åŸºæœ¬æœç´¢åŠŸèƒ½")
        search_url = f"{base_url}/paper/search"
        
        params = {
            'query': 'machine learning',
            'limit': 10,
            'fields': 'paperId,title,year,citationCount,abstract'
        }
        
        print(f"ğŸŒ è¯·æ±‚: {search_url}")
        print(f"ğŸ“‹ å‚æ•°: {params}")
        
        try:
            await asyncio.sleep(1)  # ç¤¼è²Œç­‰å¾…
            
            async with session.get(search_url, params=params) as response:
                print(f"ğŸ“¡ çŠ¶æ€ç : {response.status}")
                
                if response.status == 200:
                    data = await response.json()
                    print(f"âœ… æœç´¢æˆåŠŸ!")
                    
                    if isinstance(data, dict) and 'data' in data:
                        papers = data['data']
                        print(f"ğŸ“š æ‰¾åˆ°è®ºæ–‡: {len(papers)} ç¯‡")
                        
                        # è¿‡æ»¤æµ‹è¯•
                        filtered_papers = []
                        for paper in papers:
                            year = paper.get('year')
                            citations = paper.get('citationCount', 0)
                            title = paper.get('title', '')
                            
                            print(f"ğŸ“„ è®ºæ–‡: {title[:50]}... (å¹´ä»½:{year}, å¼•ç”¨:{citations})")
                            
                            # ç®€åŒ–è¿‡æ»¤æ¡ä»¶
                            if year and year >= 2015 and citations >= 0:
                                filtered_papers.append(paper)
                        
                        print(f"âœ… è¿‡æ»¤å: {len(filtered_papers)} ç¯‡è®ºæ–‡")
                        
                        if filtered_papers:
                            print("\nğŸ“‹ ç¬¬ä¸€ç¯‡è®ºæ–‡è¯¦æƒ…:")
                            first_paper = filtered_papers[0]
                            for key, value in first_paper.items():
                                if isinstance(value, str) and len(value) > 100:
                                    print(f"  {key}: {value[:100]}...")
                                else:
                                    print(f"  {key}: {value}")
                        
                        return filtered_papers
                    else:
                        print(f"âŒ å“åº”æ ¼å¼é”™è¯¯: {data}")
                        return None
                else:
                    text = await response.text()
                    print(f"âŒ è¯·æ±‚å¤±è´¥ {response.status}: {text[:200]}")
                    return None
                    
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            import traceback
            print(traceback.format_exc())
            return None


async def test_multiple_queries():
    """æµ‹è¯•å¤šä¸ªæŸ¥è¯¢"""
    print("\nğŸ”„ æµ‹è¯•2: å¤šæŸ¥è¯¢æœç´¢")
    
    queries = ["artificial intelligence", "deep learning", "neural networks"]
    all_results = []
    
    for query in queries:
        print(f"\nğŸ” æœç´¢: {query}")
        
        # è¿™é‡Œè°ƒç”¨ç®€åŒ–çš„æœç´¢
        base_url = "https://api.semanticscholar.org/graph/v1"
        headers = {
            'User-Agent': 'AI-Newsletter-Test/1.0',
            'Accept': 'application/json'
        }
        
        async with aiohttp.ClientSession(headers=headers) as session:
            params = {
                'query': query,
                'limit': 5,
                'fields': 'paperId,title,year,citationCount'
            }
            
            search_url = f"{base_url}/paper/search"
            
            try:
                await asyncio.sleep(2)  # é¢‘ç‡æ§åˆ¶
                
                async with session.get(search_url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        if isinstance(data, dict) and 'data' in data:
                            papers = data['data']
                            print(f"  âœ… æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
                            all_results.extend(papers)
                        else:
                            print(f"  âŒ æ•°æ®æ ¼å¼é”™è¯¯")
                    else:
                        print(f"  âŒ è¯·æ±‚å¤±è´¥: {response.status}")
                        
            except Exception as e:
                print(f"  âŒ å¼‚å¸¸: {e}")
    
    print(f"\nğŸ“Š æ€»è®¡æ‰¾åˆ°: {len(all_results)} ç¯‡è®ºæ–‡")
    return all_results


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    try:
        # æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½
        papers1 = await simple_test()
        
        if papers1:
            print(f"\nâœ… åŸºæœ¬æµ‹è¯•é€šè¿‡: {len(papers1)} ç¯‡è®ºæ–‡")
            
            # æµ‹è¯•2: å¤šæŸ¥è¯¢
            papers2 = await test_multiple_queries()
            
            print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
            print(f"   åŸºæœ¬æœç´¢: {len(papers1) if papers1 else 0} ç¯‡")
            print(f"   å¤šæŸ¥è¯¢æœç´¢: {len(papers2) if papers2 else 0} ç¯‡")
            
            # ä¿å­˜æµ‹è¯•ç»“æœ
            if papers1 or papers2:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"test_results_{timestamp}.json"
                
                test_data = {
                    'basic_search': papers1 or [],
                    'multi_query': papers2 or [],
                    'timestamp': timestamp
                }
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(test_data, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜: {filename}")
        else:
            print("\nâŒ åŸºæœ¬æµ‹è¯•å¤±è´¥")
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        print(traceback.format_exc())


if __name__ == "__main__":
    asyncio.run(main())
