# Awesome Lists AIå·¥å…·çˆ¬è™«æŠ€æœ¯æ–‡æ¡£

## ç›®æ ‡ç½‘ç«™ä¿¡æ¯

- **ç½‘ç«™åç§°**: GitHub Awesome Lists
- **ç½‘ç«™åœ°å€**: https://github.com/topics/awesome
- **ç½‘ç«™ç±»å‹**: GitHubä»“åº“é›†åˆ
- **å†…å®¹ç±»å‹**: ç²¾é€‰AIå·¥å…·å’Œèµ„æºåˆ—è¡¨
- **æ›´æ–°é¢‘ç‡**: æŒç»­æ›´æ–°
- **è¯­è¨€**: å¤šè¯­è¨€ï¼ˆä¸»è¦è‹±æ–‡ï¼‰
- **ç‰¹ç‚¹**: ç¤¾åŒºç»´æŠ¤ã€é«˜è´¨é‡èµ„æºã€åˆ†ç±»è¯¦ç»†

## çˆ¬è™«æ–¹æ¡ˆæ¦‚è¿°

### æŠ€æœ¯æ¶æ„
- **çˆ¬è™«ç±»å‹**: GitHub API + ç½‘é¡µçˆ¬è™«
- **ä¸»è¦æŠ€æœ¯**: Python + GitHub API + requests + BeautifulSoup
- **æ•°æ®æ ¼å¼**: JSON â†’ Markdown â†’ ç»“æ„åŒ–æ•°æ®
- **ç‰¹è‰²åŠŸèƒ½**: å¤šä»“åº“èšåˆã€å·¥å…·åˆ†ç±»ã€è´¨é‡è¯„ä¼°

### æ ¸å¿ƒåŠŸèƒ½
1. **Awesomeä»“åº“å‘ç°**: è‡ªåŠ¨å‘ç°AIç›¸å…³çš„awesomeåˆ—è¡¨
2. **å·¥å…·æå–**: ä»READMEæ–‡ä»¶ä¸­æå–å·¥å…·ä¿¡æ¯
3. **åˆ†ç±»æ•´ç†**: æŒ‰åŠŸèƒ½å’ŒæŠ€æœ¯æ ˆåˆ†ç±»
4. **è´¨é‡è¯„ä¼°**: åŸºäºGitHubæŒ‡æ ‡è¯„ä¼°å·¥å…·è´¨é‡
5. **æ›´æ–°ç›‘æ§**: ç›‘æ§åˆ—è¡¨æ›´æ–°å’Œæ–°å·¥å…·æ·»åŠ 
6. **å»é‡åˆå¹¶**: è·¨ä»“åº“å·¥å…·å»é‡å’Œä¿¡æ¯åˆå¹¶

## çˆ¬å–æ–¹å¼è¯¦è§£

### 1. ç›®æ ‡Awesome Lists

#### ä¸»è¦AIç›¸å…³Awesome Lists
```python
AWESOME_AI_REPOS = {
    'general': [
        'josephmisiti/awesome-machine-learning',
        'ChristosChristofidis/awesome-deep-learning',
        'owainlewis/awesome-artificial-intelligence',
        'academic/awesome-datascience',
        'ujjwalkarn/Machine-Learning-Tutorials'
    ],
    'frameworks': [
        'ritchieng/the-incredible-pytorch',
        'tensorflow/awesome-tensorflow',
        'huggingface/awesome-huggingface',
        'ml-tooling/best-of-ml-python'
    ],
    'nlp': [
        'keon/awesome-nlp',
        'brianspiering/awesome-dl4nlp',
        'sebastianruder/NLP-progress'
    ],
    'computer_vision': [
        'jbhuang0604/awesome-computer-vision',
        'kjw0612/awesome-deep-vision',
        'weecology/awesome-open-science'
    ],
    'tools': [
        'ml-tooling/best-of-ml-python',
        'EthicalML/awesome-production-machine-learning',
        'eugeneyan/applied-ml'
    ],
    'datasets': [
        'awesomedata/awesome-public-datasets',
        'caesar0301/awesome-public-datasets',
        'academic/awesome-datascience'
    ]
}

GITHUB_CONFIG = {
    'api_base': 'https://api.github.com',
    'search_endpoint': '/search/repositories',
    'repo_endpoint': '/repos/{owner}/{repo}',
    'contents_endpoint': '/repos/{owner}/{repo}/contents/{path}',
    'rate_limit': 5000,  # æ¯å°æ—¶è¯·æ±‚é™åˆ¶
    'headers': {
        'Accept': 'application/vnd.github.v3+json',
        'User-Agent': 'AwesomeListsSpider/1.0'
    }
}
```

### 2. Awesome Lists çˆ¬è™«å®ç°

#### ä¸»çˆ¬è™«ç±»
```python
import requests
import re
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Set
from urllib.parse import urlparse, urljoin
import logging
from dataclasses import dataclass
from bs4 import BeautifulSoup
import base64
import yaml

@dataclass
class AITool:
    name: str
    description: str
    url: str
    category: str
    subcategory: str = ''
    github_url: str = ''
    stars: int = 0
    language: str = ''
    license: str = ''
    last_updated: str = ''
    tags: List[str] = None
    source_repo: str = ''
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = []

class AwesomeListsSpider:
    def __init__(self, github_token: Optional[str] = None):
        self.github_token = github_token
        self.session = requests.Session()
        
        # è®¾ç½®GitHub API headers
        headers = {
            'Accept': 'application/vnd.github.v3+json',
            'User-Agent': 'AwesomeListsSpider/1.0'
        }
        
        if github_token:
            headers['Authorization'] = f'token {github_token}'
        
        self.session.headers.update(headers)
        
        self.logger = logging.getLogger("AwesomeListsSpider")
        self.rate_limit_remaining = 5000
        self.rate_limit_reset = time.time() + 3600
        
        # å·¥å…·å»é‡é›†åˆ
        self.seen_tools: Set[str] = set()
        self.all_tools: List[AITool] = []
    
    def check_rate_limit(self):
        """æ£€æŸ¥GitHub APIé€Ÿç‡é™åˆ¶"""
        if self.rate_limit_remaining <= 10:
            sleep_time = max(0, self.rate_limit_reset - time.time())
            if sleep_time > 0:
                self.logger.info(f"Rate limit reached, sleeping for {sleep_time:.0f} seconds")
                time.sleep(sleep_time)
                self.rate_limit_remaining = 5000
                self.rate_limit_reset = time.time() + 3600
    
    def github_api_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:
        """å‘é€GitHub APIè¯·æ±‚"""
        self.check_rate_limit()
        
        url = f"https://api.github.com{endpoint}"
        
        try:
            response = self.session.get(url, params=params, timeout=30)
            
            # æ›´æ–°é€Ÿç‡é™åˆ¶ä¿¡æ¯
            self.rate_limit_remaining = int(response.headers.get('X-RateLimit-Remaining', 0))
            self.rate_limit_reset = int(response.headers.get('X-RateLimit-Reset', time.time() + 3600))
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            self.logger.error(f"GitHub API request failed: {e}")
            return None
    
    def discover_awesome_repos(self, query: str = "awesome machine learning") -> List[Dict]:
        """å‘ç°awesomeä»“åº“"""
        self.logger.info(f"Discovering awesome repos with query: {query}")
        
        params = {
            'q': f'{query} in:name,description topic:awesome',
            'sort': 'stars',
            'order': 'desc',
            'per_page': 100
        }
        
        result = self.github_api_request('/search/repositories', params)
        
        if not result:
            return []
        
        repos = []
        for item in result.get('items', []):
            repo_info = {
                'full_name': item['full_name'],
                'name': item['name'],
                'description': item.get('description', ''),
                'stars': item['stargazers_count'],
                'language': item.get('language', ''),
                'updated_at': item['updated_at'],
                'html_url': item['html_url'],
                'topics': item.get('topics', [])
            }
            repos.append(repo_info)
        
        self.logger.info(f"Found {len(repos)} awesome repositories")
        return repos
    
    def get_repo_readme(self, owner: str, repo: str) -> Optional[str]:
        """è·å–ä»“åº“READMEå†…å®¹"""
        # å°è¯•ä¸åŒçš„READMEæ–‡ä»¶å
        readme_files = ['README.md', 'readme.md', 'README.rst', 'README.txt', 'README']
        
        for readme_file in readme_files:
            endpoint = f'/repos/{owner}/{repo}/contents/{readme_file}'
            result = self.github_api_request(endpoint)
            
            if result and result.get('content'):
                try:
                    # GitHub APIè¿”å›base64ç¼–ç çš„å†…å®¹
                    content = base64.b64decode(result['content']).decode('utf-8')
                    return content
                except Exception as e:
                    self.logger.warning(f"Failed to decode README for {owner}/{repo}: {e}")
                    continue
        
        self.logger.warning(f"No README found for {owner}/{repo}")
        return None
    
    def parse_awesome_list(self, content: str, source_repo: str) -> List[AITool]:
        """è§£æawesomeåˆ—è¡¨å†…å®¹"""
        tools = []
        
        if not content:
            return tools
        
        # æŒ‰è¡Œåˆ†æ
        lines = content.split('\n')
        current_category = 'General'
        current_subcategory = ''
        
        for line in lines:
            line = line.strip()
            
            # æ£€æµ‹åˆ†ç±»æ ‡é¢˜
            if line.startswith('#'):
                category_match = re.match(r'^#+\s*(.+)$', line)
                if category_match:
                    category_text = category_match.group(1).strip()
                    
                    # åˆ¤æ–­æ˜¯ä¸»åˆ†ç±»è¿˜æ˜¯å­åˆ†ç±»
                    if line.startswith('##'):
                        current_category = self.normalize_category(category_text)
                        current_subcategory = ''
                    elif line.startswith('###'):
                        current_subcategory = self.normalize_category(category_text)
                continue
            
            # æ£€æµ‹å·¥å…·é“¾æ¥
            tool_match = re.search(r'\[([^\]]+)\]\(([^)]+)\)\s*-?\s*(.*)$', line)
            if tool_match:
                name = tool_match.group(1).strip()
                url = tool_match.group(2).strip()
                description = tool_match.group(3).strip()
                
                # æ¸…ç†æè¿°
                description = re.sub(r'^-+\s*', '', description)
                description = re.sub(r'\s*\.$', '', description)
                
                # è¿‡æ»¤æ— æ•ˆé“¾æ¥
                if not self.is_valid_tool_url(url):
                    continue
                
                # åˆ›å»ºå·¥å…·å¯¹è±¡
                tool = AITool(
                    name=name,
                    description=description,
                    url=url,
                    category=current_category,
                    subcategory=current_subcategory,
                    source_repo=source_repo
                )
                
                # å¦‚æœæ˜¯GitHubé“¾æ¥ï¼Œè·å–é¢å¤–ä¿¡æ¯
                if 'github.com' in url:
                    tool.github_url = url
                    github_info = self.get_github_repo_info(url)
                    if github_info:
                        tool.stars = github_info.get('stars', 0)
                        tool.language = github_info.get('language', '')
                        tool.license = github_info.get('license', '')
                        tool.last_updated = github_info.get('updated_at', '')
                
                # ç”Ÿæˆå·¥å…·æ ‡ç­¾
                tool.tags = self.generate_tool_tags(tool)
                
                # å»é‡æ£€æŸ¥
                tool_key = f"{tool.name.lower()}_{tool.url}"
                if tool_key not in self.seen_tools:
                    self.seen_tools.add(tool_key)
                    tools.append(tool)
        
        return tools
    
    def normalize_category(self, category: str) -> str:
        """æ ‡å‡†åŒ–åˆ†ç±»åç§°"""
        category = category.lower().strip()
        
        # åˆ†ç±»æ˜ å°„
        category_mapping = {
            'machine learning': 'Machine Learning',
            'deep learning': 'Deep Learning',
            'natural language processing': 'NLP',
            'nlp': 'NLP',
            'computer vision': 'Computer Vision',
            'cv': 'Computer Vision',
            'data science': 'Data Science',
            'data analysis': 'Data Analysis',
            'visualization': 'Data Visualization',
            'frameworks': 'Frameworks',
            'libraries': 'Libraries',
            'tools': 'Tools',
            'datasets': 'Datasets',
            'courses': 'Education',
            'tutorials': 'Education',
            'books': 'Education',
            'papers': 'Research',
            'research': 'Research'
        }
        
        for key, value in category_mapping.items():
            if key in category:
                return value
        
        # é¦–å­—æ¯å¤§å†™
        return ' '.join(word.capitalize() for word in category.split())
    
    def is_valid_tool_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å·¥å…·URL"""
        if not url or url.startswith('#'):
            return False
        
        # æ’é™¤çš„URLæ¨¡å¼
        excluded_patterns = [
            r'mailto:',
            r'javascript:',
            r'#[a-zA-Z]',  # é”šç‚¹é“¾æ¥
            r'\.(jpg|jpeg|png|gif|svg)$',  # å›¾ç‰‡æ–‡ä»¶
            r'/blob/master/.*\.(md|txt)$'  # æ–‡æ¡£æ–‡ä»¶
        ]
        
        for pattern in excluded_patterns:
            if re.search(pattern, url, re.IGNORECASE):
                return False
        
        return True
    
    def get_github_repo_info(self, github_url: str) -> Optional[Dict]:
        """è·å–GitHubä»“åº“ä¿¡æ¯"""
        # è§£æGitHub URL
        match = re.search(r'github\.com/([^/]+)/([^/]+)', github_url)
        if not match:
            return None
        
        owner, repo = match.groups()
        repo = repo.rstrip('/')
        
        endpoint = f'/repos/{owner}/{repo}'
        result = self.github_api_request(endpoint)
        
        if result:
            return {
                'stars': result.get('stargazers_count', 0),
                'language': result.get('language', ''),
                'license': result.get('license', {}).get('name', '') if result.get('license') else '',
                'updated_at': result.get('updated_at', ''),
                'description': result.get('description', ''),
                'topics': result.get('topics', [])
            }
        
        return None
    
    def generate_tool_tags(self, tool: AITool) -> List[str]:
        """ç”Ÿæˆå·¥å…·æ ‡ç­¾"""
        tags = []
        
        # åŸºäºåˆ†ç±»çš„æ ‡ç­¾
        if tool.category:
            tags.append(tool.category.lower().replace(' ', '-'))
        
        if tool.subcategory:
            tags.append(tool.subcategory.lower().replace(' ', '-'))
        
        # åŸºäºç¼–ç¨‹è¯­è¨€çš„æ ‡ç­¾
        if tool.language:
            tags.append(tool.language.lower())
        
        # åŸºäºæè¿°çš„æ ‡ç­¾
        description_text = (tool.name + ' ' + tool.description).lower()
        
        # æŠ€æœ¯æ ‡ç­¾
        tech_keywords = {
            'python': ['python', 'py'],
            'javascript': ['javascript', 'js', 'node'],
            'tensorflow': ['tensorflow', 'tf'],
            'pytorch': ['pytorch', 'torch'],
            'scikit-learn': ['sklearn', 'scikit-learn'],
            'api': ['api', 'rest', 'graphql'],
            'web': ['web', 'webapp', 'website'],
            'cli': ['cli', 'command-line', 'terminal'],
            'gui': ['gui', 'desktop', 'interface'],
            'cloud': ['cloud', 'aws', 'azure', 'gcp'],
            'docker': ['docker', 'container'],
            'jupyter': ['jupyter', 'notebook'],
            'visualization': ['viz', 'plot', 'chart', 'graph']
        }
        
        for tag, keywords in tech_keywords.items():
            if any(keyword in description_text for keyword in keywords):
                tags.append(tag)
        
        # åŠŸèƒ½æ ‡ç­¾
        function_keywords = {
            'training': ['train', 'training', 'fit'],
            'inference': ['inference', 'predict', 'deploy'],
            'preprocessing': ['preprocess', 'clean', 'transform'],
            'evaluation': ['eval', 'metric', 'benchmark'],
            'monitoring': ['monitor', 'track', 'log'],
            'optimization': ['optim', 'tune', 'hyperparameter']
        }
        
        for tag, keywords in function_keywords.items():
            if any(keyword in description_text for keyword in keywords):
                tags.append(tag)
        
        return list(set(tags))  # å»é‡
    
    def crawl_awesome_lists(self, repo_list: List[str] = None) -> List[AITool]:
        """çˆ¬å–awesomeåˆ—è¡¨"""
        if repo_list is None:
            # ä½¿ç”¨é»˜è®¤çš„ä»“åº“åˆ—è¡¨
            repo_list = []
            for category_repos in AWESOME_AI_REPOS.values():
                repo_list.extend(category_repos)
        
        all_tools = []
        
        for repo_full_name in repo_list:
            try:
                self.logger.info(f"Processing repository: {repo_full_name}")
                
                owner, repo = repo_full_name.split('/')
                
                # è·å–READMEå†…å®¹
                readme_content = self.get_repo_readme(owner, repo)
                if not readme_content:
                    continue
                
                # è§£æå·¥å…·åˆ—è¡¨
                tools = self.parse_awesome_list(readme_content, repo_full_name)
                
                self.logger.info(f"Found {len(tools)} tools in {repo_full_name}")
                all_tools.extend(tools)
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                time.sleep(1)
                
            except Exception as e:
                self.logger.error(f"Error processing {repo_full_name}: {e}")
                continue
        
        # åˆå¹¶å’Œå»é‡
        merged_tools = self.merge_duplicate_tools(all_tools)
        
        self.logger.info(f"Total unique tools found: {len(merged_tools)}")
        return merged_tools
    
    def merge_duplicate_tools(self, tools: List[AITool]) -> List[AITool]:
        """åˆå¹¶é‡å¤å·¥å…·"""
        tool_map = {}
        
        for tool in tools:
            # ä½¿ç”¨URLä½œä¸ºä¸»é”®
            key = tool.url.lower().strip('/')
            
            if key in tool_map:
                # åˆå¹¶ä¿¡æ¯
                existing = tool_map[key]
                
                # é€‰æ‹©æ›´è¯¦ç»†çš„æè¿°
                if len(tool.description) > len(existing.description):
                    existing.description = tool.description
                
                # åˆå¹¶æ ‡ç­¾
                existing.tags = list(set(existing.tags + tool.tags))
                
                # é€‰æ‹©æ›´é«˜çš„æ˜Ÿæ•°
                if tool.stars > existing.stars:
                    existing.stars = tool.stars
                    existing.language = tool.language
                    existing.license = tool.license
                    existing.last_updated = tool.last_updated
                
                # è®°å½•æ¥æºä»“åº“
                if tool.source_repo not in existing.source_repo:
                    existing.source_repo += f", {tool.source_repo}"
            else:
                tool_map[key] = tool
        
        return list(tool_map.values())
    
    def categorize_tools(self, tools: List[AITool]) -> Dict[str, List[AITool]]:
        """æŒ‰åˆ†ç±»æ•´ç†å·¥å…·"""
        categorized = {}
        
        for tool in tools:
            category = tool.category or 'Other'
            
            if category not in categorized:
                categorized[category] = []
            
            categorized[category].append(tool)
        
        # æŒ‰æ˜Ÿæ•°æ’åºæ¯ä¸ªåˆ†ç±»
        for category in categorized:
            categorized[category].sort(key=lambda x: x.stars, reverse=True)
        
        return categorized
    
    def filter_high_quality_tools(self, tools: List[AITool], min_stars: int = 100) -> List[AITool]:
        """è¿‡æ»¤é«˜è´¨é‡å·¥å…·"""
        high_quality = []
        
        for tool in tools:
            # è´¨é‡è¯„ä¼°æ ‡å‡†
            quality_score = 0
            
            # GitHubæ˜Ÿæ•°
            if tool.stars >= 1000:
                quality_score += 3
            elif tool.stars >= 500:
                quality_score += 2
            elif tool.stars >= min_stars:
                quality_score += 1
            
            # æè¿°è´¨é‡
            if len(tool.description) > 50:
                quality_score += 1
            
            # æœ€è¿‘æ›´æ–°
            if tool.last_updated:
                try:
                    last_update = datetime.fromisoformat(tool.last_updated.replace('Z', '+00:00'))
                    if (datetime.now() - last_update.replace(tzinfo=None)).days < 365:
                        quality_score += 1
                except:
                    pass
            
            # æœ‰è®¸å¯è¯
            if tool.license:
                quality_score += 1
            
            # è´¨é‡é˜ˆå€¼
            if quality_score >= 3:
                high_quality.append(tool)
        
        return high_quality
    
    def generate_report(self, tools: List[AITool]) -> Dict:
        """ç”Ÿæˆçˆ¬å–æŠ¥å‘Š"""
        categorized = self.categorize_tools(tools)
        
        report = {
            'summary': {
                'total_tools': len(tools),
                'total_categories': len(categorized),
                'avg_stars': sum(tool.stars for tool in tools) / len(tools) if tools else 0,
                'top_languages': self.get_top_languages(tools),
                'crawl_timestamp': datetime.now().isoformat()
            },
            'categories': {},
            'top_tools': sorted(tools, key=lambda x: x.stars, reverse=True)[:20]
        }
        
        for category, category_tools in categorized.items():
            report['categories'][category] = {
                'count': len(category_tools),
                'avg_stars': sum(tool.stars for tool in category_tools) / len(category_tools),
                'top_tools': category_tools[:10]
            }
        
        return report
    
    def get_top_languages(self, tools: List[AITool], top_n: int = 10) -> List[Dict]:
        """è·å–çƒ­é—¨ç¼–ç¨‹è¯­è¨€"""
        language_count = {}
        
        for tool in tools:
            if tool.language:
                language_count[tool.language] = language_count.get(tool.language, 0) + 1
        
        sorted_languages = sorted(language_count.items(), key=lambda x: x[1], reverse=True)
        
        return [
            {'language': lang, 'count': count}
            for lang, count in sorted_languages[:top_n]
        ]
    
    def export_tools(self, tools: List[AITool], format: str = 'json') -> str:
        """å¯¼å‡ºå·¥å…·æ•°æ®"""
        if format == 'json':
            return json.dumps([tool.__dict__ for tool in tools], indent=2, ensure_ascii=False)
        
        elif format == 'markdown':
            categorized = self.categorize_tools(tools)
            
            md_content = ["# AI Tools Collection\n"]
            
            for category, category_tools in categorized.items():
                md_content.append(f"## {category}\n")
                
                for tool in category_tools:
                    stars_badge = f"â­ {tool.stars}" if tool.stars > 0 else ""
                    language_badge = f"ğŸ“ {tool.language}" if tool.language else ""
                    
                    md_content.append(
                        f"- **[{tool.name}]({tool.url})** {stars_badge} {language_badge}\n"
                        f"  {tool.description}\n"
                    )
                
                md_content.append("\n")
            
            return ''.join(md_content)
        
        elif format == 'csv':
            import csv
            import io
            
            output = io.StringIO()
            writer = csv.writer(output)
            
            # å†™å…¥æ ‡é¢˜è¡Œ
            writer.writerow([
                'Name', 'Description', 'URL', 'Category', 'Subcategory',
                'GitHub URL', 'Stars', 'Language', 'License', 'Last Updated',
                'Tags', 'Source Repo'
            ])
            
            # å†™å…¥æ•°æ®è¡Œ
            for tool in tools:
                writer.writerow([
                    tool.name, tool.description, tool.url, tool.category,
                    tool.subcategory, tool.github_url, tool.stars,
                    tool.language, tool.license, tool.last_updated,
                    ', '.join(tool.tags), tool.source_repo
                ])
            
            return output.getvalue()
        
        else:
            raise ValueError(f"Unsupported format: {format}")
```

### 3. å·¥å…·è´¨é‡è¯„ä¼°å™¨

```python
class ToolQualityAssessor:
    def __init__(self):
        self.quality_metrics = {
            'popularity': 0.3,
            'activity': 0.25,
            'documentation': 0.2,
            'community': 0.15,
            'maturity': 0.1
        }
    
    def assess_tool_quality(self, tool: AITool, github_data: Dict = None) -> float:
        """è¯„ä¼°å·¥å…·è´¨é‡"""
        score = 0.0
        
        # æµè¡Œåº¦è¯„åˆ†ï¼ˆåŸºäºGitHubæ˜Ÿæ•°ï¼‰
        popularity_score = self.calculate_popularity_score(tool.stars)
        score += popularity_score * self.quality_metrics['popularity']
        
        # æ´»è·ƒåº¦è¯„åˆ†ï¼ˆåŸºäºæœ€è¿‘æ›´æ–°æ—¶é—´ï¼‰
        activity_score = self.calculate_activity_score(tool.last_updated)
        score += activity_score * self.quality_metrics['activity']
        
        # æ–‡æ¡£è´¨é‡è¯„åˆ†
        doc_score = self.calculate_documentation_score(tool.description, github_data)
        score += doc_score * self.quality_metrics['documentation']
        
        # ç¤¾åŒºè¯„åˆ†ï¼ˆåŸºäºGitHubæ•°æ®ï¼‰
        community_score = self.calculate_community_score(github_data)
        score += community_score * self.quality_metrics['community']
        
        # æˆç†Ÿåº¦è¯„åˆ†
        maturity_score = self.calculate_maturity_score(tool, github_data)
        score += maturity_score * self.quality_metrics['maturity']
        
        return min(score, 10.0)  # é™åˆ¶åœ¨0-10åˆ†
    
    def calculate_popularity_score(self, stars: int) -> float:
        """è®¡ç®—æµè¡Œåº¦åˆ†æ•°"""
        if stars >= 10000:
            return 10.0
        elif stars >= 5000:
            return 8.0
        elif stars >= 1000:
            return 6.0
        elif stars >= 500:
            return 4.0
        elif stars >= 100:
            return 2.0
        else:
            return 1.0
    
    def calculate_activity_score(self, last_updated: str) -> float:
        """è®¡ç®—æ´»è·ƒåº¦åˆ†æ•°"""
        if not last_updated:
            return 1.0
        
        try:
            last_update = datetime.fromisoformat(last_updated.replace('Z', '+00:00'))
            days_ago = (datetime.now() - last_update.replace(tzinfo=None)).days
            
            if days_ago <= 30:
                return 10.0
            elif days_ago <= 90:
                return 8.0
            elif days_ago <= 180:
                return 6.0
            elif days_ago <= 365:
                return 4.0
            elif days_ago <= 730:
                return 2.0
            else:
                return 1.0
        except:
            return 1.0
    
    def calculate_documentation_score(self, description: str, github_data: Dict = None) -> float:
        """è®¡ç®—æ–‡æ¡£è´¨é‡åˆ†æ•°"""
        score = 0.0
        
        # æè¿°é•¿åº¦å’Œè´¨é‡
        if len(description) > 100:
            score += 3.0
        elif len(description) > 50:
            score += 2.0
        elif len(description) > 20:
            score += 1.0
        
        # GitHub READMEè´¨é‡ï¼ˆå¦‚æœæœ‰GitHubæ•°æ®ï¼‰
        if github_data:
            readme_size = github_data.get('readme_size', 0)
            if readme_size > 5000:
                score += 3.0
            elif readme_size > 2000:
                score += 2.0
            elif readme_size > 500:
                score += 1.0
        
        return min(score, 10.0)
    
    def calculate_community_score(self, github_data: Dict = None) -> float:
        """è®¡ç®—ç¤¾åŒºæ´»è·ƒåº¦åˆ†æ•°"""
        if not github_data:
            return 1.0
        
        score = 0.0
        
        # Issueså’ŒPRæ•°é‡
        open_issues = github_data.get('open_issues_count', 0)
        if open_issues > 0:
            score += 2.0
        
        # Forkæ•°é‡
        forks = github_data.get('forks_count', 0)
        if forks >= 100:
            score += 3.0
        elif forks >= 50:
            score += 2.0
        elif forks >= 10:
            score += 1.0
        
        # è´¡çŒ®è€…æ•°é‡ï¼ˆéœ€è¦é¢å¤–APIè°ƒç”¨ï¼‰
        contributors = github_data.get('contributors_count', 0)
        if contributors >= 10:
            score += 2.0
        elif contributors >= 5:
            score += 1.0
        
        return min(score, 10.0)
    
    def calculate_maturity_score(self, tool: AITool, github_data: Dict = None) -> float:
        """è®¡ç®—é¡¹ç›®æˆç†Ÿåº¦åˆ†æ•°"""
        score = 0.0
        
        # è®¸å¯è¯
        if tool.license:
            score += 2.0
        
        # ç¼–ç¨‹è¯­è¨€ï¼ˆæŸäº›è¯­è¨€è¡¨æ˜æ›´é«˜æˆç†Ÿåº¦ï¼‰
        mature_languages = ['Python', 'Java', 'C++', 'JavaScript', 'Go', 'Rust']
        if tool.language in mature_languages:
            score += 2.0
        
        # GitHubæ•°æ®
        if github_data:
            # å‘å¸ƒç‰ˆæœ¬
            if github_data.get('has_releases', False):
                score += 2.0
            
            # é¡¹ç›®å¹´é¾„
            created_at = github_data.get('created_at')
            if created_at:
                try:
                    created_date = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                    age_days = (datetime.now() - created_date.replace(tzinfo=None)).days
                    
                    if age_days >= 730:  # 2å¹´ä»¥ä¸Š
                        score += 2.0
                    elif age_days >= 365:  # 1å¹´ä»¥ä¸Š
                        score += 1.0
                except:
                    pass
        
        return min(score, 10.0)
```

## åçˆ¬è™«åº”å¯¹ç­–ç•¥

### 1. GitHub APIé™åˆ¶å¤„ç†
```python
class GitHubRateLimiter:
    def __init__(self, token: str = None):
        self.token = token
        self.requests_made = 0
        self.reset_time = time.time() + 3600
        
        # æœ‰tokenæ—¶é™åˆ¶æ›´é«˜
        self.rate_limit = 5000 if token else 60
    
    def wait_if_needed(self):
        if self.requests_made >= self.rate_limit:
            sleep_time = max(0, self.reset_time - time.time())
            if sleep_time > 0:
                time.sleep(sleep_time)
                self.requests_made = 0
                self.reset_time = time.time() + 3600
```

### 2. æ™ºèƒ½é‡è¯•æœºåˆ¶
```python
def retry_request(func, max_retries: int = 3, backoff_factor: float = 2.0):
    """æ™ºèƒ½é‡è¯•è£…é¥°å™¨"""
    for attempt in range(max_retries):
        try:
            return func()
        except requests.exceptions.RequestException as e:
            if attempt == max_retries - 1:
                raise e
            
            wait_time = backoff_factor ** attempt
            time.sleep(wait_time)
    
    return None
```

## é…ç½®å‚æ•°

### çˆ¬è™«é…ç½®
```python
AWESOME_SPIDER_CONFIG = {
    'github_settings': {
        'token': None,  # GitHub Personal Access Token
        'rate_limit_buffer': 100,
        'max_retries': 3,
        'timeout': 30
    },
    'crawl_settings': {
        'max_repos_per_search': 100,
        'min_stars_threshold': 10,
        'include_archived': False,
        'max_tools_per_repo': 1000
    },
    'quality_filters': {
        'min_description_length': 20,
        'require_github_url': False,
        'min_quality_score': 3.0
    },
    'output_settings': {
        'export_formats': ['json', 'markdown', 'csv'],
        'include_metadata': True,
        'sort_by': 'stars'  # stars, name, category
    }
}
```

## æ•°æ®è¾“å‡ºæ ¼å¼

### JSONæ ¼å¼
```json
{
  "name": "TensorFlow",
  "description": "An Open Source Machine Learning Framework for Everyone",
  "url": "https://tensorflow.org",
  "category": "Deep Learning",
  "subcategory": "Frameworks",
  "github_url": "https://github.com/tensorflow/tensorflow",
  "stars": 185000,
  "language": "C++",
  "license": "Apache-2.0",
  "last_updated": "2024-01-15T10:30:00Z",
  "tags": ["deep-learning", "machine-learning", "tensorflow", "python", "c++"],
  "source_repo": "josephmisiti/awesome-machine-learning",
  "quality_score": 9.8,
  "metadata": {
    "crawl_timestamp": "2024-01-15T12:00:00Z",
    "extraction_method": "github_api",
    "spider_version": "1.0"
  }
}
```

## å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 1. GitHub APIé™åˆ¶
**é—®é¢˜**: APIè¯·æ±‚é¢‘ç‡é™åˆ¶
**è§£å†³**: 
- ä½¿ç”¨Personal Access Token
- å®ç°æ™ºèƒ½é€Ÿç‡é™åˆ¶
- ç¼“å­˜APIå“åº”

### 2. READMEè§£æå›°éš¾
**é—®é¢˜**: ä¸åŒä»“åº“çš„READMEæ ¼å¼å·®å¼‚å¾ˆå¤§
**è§£å†³**: 
- ä½¿ç”¨å¤šç§è§£æç­–ç•¥
- å®ç°æ¨¡ç³ŠåŒ¹é…
- äººå·¥è§„åˆ™è¡¥å……

### 3. å·¥å…·ä¿¡æ¯ä¸å®Œæ•´
**é—®é¢˜**: æŸäº›å·¥å…·ç¼ºå°‘å…³é”®ä¿¡æ¯
**è§£å†³**: 
- å¤šæºæ•°æ®åˆå¹¶
- ç½‘ç«™ç›´æ¥è®¿é—®è¡¥å……
- ç¤¾åŒºæ•°æ®æºæ•´åˆ

### 4. åˆ†ç±»ä¸å‡†ç¡®
**é—®é¢˜**: è‡ªåŠ¨åˆ†ç±»å¯èƒ½ä¸å‡†ç¡®
**è§£å†³**: 
- ä½¿ç”¨æœºå™¨å­¦ä¹ åˆ†ç±»
- å»ºç«‹åˆ†ç±»è§„åˆ™åº“
- äººå·¥å®¡æ ¸æœºåˆ¶

## ç»´æŠ¤å»ºè®®

### å®šæœŸç»´æŠ¤ä»»åŠ¡
1. **ä»“åº“åˆ—è¡¨æ›´æ–°**: å®šæœŸå‘ç°æ–°çš„awesomeä»“åº“
2. **å·¥å…·ä¿¡æ¯æ›´æ–°**: æ›´æ–°GitHubç»Ÿè®¡æ•°æ®
3. **åˆ†ç±»ä¼˜åŒ–**: ä¼˜åŒ–å·¥å…·åˆ†ç±»ç®—æ³•
4. **è´¨é‡è¯„ä¼°**: è°ƒæ•´è´¨é‡è¯„ä¼°æ ‡å‡†

### æ‰©å±•æ–¹å‘
1. **å¤šå¹³å°æ”¯æŒ**: æ”¯æŒGitLabã€Bitbucketç­‰å¹³å°
2. **æ™ºèƒ½æ¨è**: åŸºäºç”¨æˆ·å…´è¶£æ¨èå·¥å…·
3. **è¶‹åŠ¿åˆ†æ**: åˆ†æAIå·¥å…·å‘å±•è¶‹åŠ¿
4. **ç¤¾åŒºé›†æˆ**: é›†æˆStack Overflowã€Redditç­‰ç¤¾åŒºæ•°æ®

## ç›¸å…³èµ„æº

- [GitHub API Documentation](https://docs.github.com/en/rest)
- [Awesome Lists Guidelines](https://github.com/sindresorhus/awesome)
- [GitHub Search Syntax](https://docs.github.com/en/search-github/searching-on-github)
- [GitHub Rate Limiting](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting)