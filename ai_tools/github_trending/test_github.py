#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitHub Trendingçˆ¬è™«æµ‹è¯•è„šæœ¬
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from spider import GitHubTrendingSpider
import json
from datetime import datetime


def test_github_crawler():
    """æµ‹è¯•GitHubçˆ¬è™«"""
    print("ğŸ™ GitHub Trending AIå·¥å…·çˆ¬è™«æµ‹è¯•")
    print("=" * 50)
    
    try:
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        spider = GitHubTrendingSpider()
        
        # æµ‹è¯•çˆ¬å–Pythonç›¸å…³çš„æ¯æ—¥è¶‹åŠ¿
        print("ğŸ çˆ¬å–Pythonç›¸å…³çš„AIå·¥å…· (æ¯æ—¥è¶‹åŠ¿)...")
        repos = spider.get_trending_repos(language='python', since='daily')
        
        print(f"âœ… æ‰¾åˆ° {len(repos)} ä¸ªAIç›¸å…³çš„Pythonå·¥å…·")
        
        if repos:
            print("\nğŸ“Š å‰3ä¸ªå·¥å…·:")
            for i, repo in enumerate(repos[:3], 1):
                print(f"\n{i}. {repo.get('name', 'Unknown')}")
                print(f"   æè¿°: {repo.get('description', 'æ— æè¿°')[:100]}...")
                print(f"   Stars: {repo.get('stars', 0):,} (+{repo.get('stars_today', 0)} ä»Šæ—¥)")
                print(f"   è¯­è¨€: {repo.get('language', 'Unknown')}")
                print(f"   é“¾æ¥: {repo.get('url', 'æ— é“¾æ¥')}")
                
                if repo.get('quality_score'):
                    score = repo['quality_score'].get('total_score', 0)
                    print(f"   è´¨é‡è¯„åˆ†: {score:.1f}/100")
            
            # ä¿å­˜æµ‹è¯•ç»“æœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            test_file = f"test_results_{timestamp}.json"
            
            try:
                with open(test_file, 'w', encoding='utf-8') as f:
                    json.dump(repos, f, ensure_ascii=False, indent=2)
                print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜: {test_file}")
            except Exception as e:
                print(f"\nâš ï¸ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            
            return True
        else:
            print("âŒ æœªæ‰¾åˆ°AIç›¸å…³å·¥å…·")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_multiple_languages():
    """æµ‹è¯•å¤šç§ç¼–ç¨‹è¯­è¨€"""
    print("\nğŸŒ æµ‹è¯•å¤šç§ç¼–ç¨‹è¯­è¨€çš„AIå·¥å…·")
    print("-" * 30)
    
    spider = GitHubTrendingSpider()
    languages = ['python', 'javascript', None]  # Noneè¡¨ç¤ºæ‰€æœ‰è¯­è¨€
    all_results = {}
    
    for lang in languages:
        lang_name = lang or "all_languages"
        print(f"\nğŸ” çˆ¬å– {lang_name} çš„AIå·¥å…·...")
        
        try:
            repos = spider.get_trending_repos(language=lang, since='daily')
            all_results[lang_name] = repos
            print(f"  âœ… æ‰¾åˆ° {len(repos)} ä¸ªå·¥å…·")
            
            # æ˜¾ç¤ºæœ€çƒ­é—¨çš„å·¥å…·
            if repos:
                top_repo = max(repos, key=lambda x: x.get('stars', 0))
                print(f"  ğŸŒŸ æœ€çƒ­é—¨: {top_repo.get('name')} ({top_repo.get('stars', 0):,} stars)")
            
        except Exception as e:
            print(f"  âŒ çˆ¬å–å¤±è´¥: {e}")
            all_results[lang_name] = []
    
    # ç»Ÿè®¡æ€»ç»“
    total_repos = sum(len(repos) for repos in all_results.values())
    print(f"\nğŸ“ˆ æ€»ç»“:")
    print(f"   æ€»å·¥å…·æ•°: {total_repos}")
    for lang, repos in all_results.items():
        print(f"   {lang}: {len(repos)} ä¸ªå·¥å…·")
    
    return all_results


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹GitHubçˆ¬è™«æµ‹è¯•...")
    
    # åŸºç¡€æµ‹è¯•
    success = test_github_crawler()
    
    if success:
        print("\n" + "="*50)
        # æ‰©å±•æµ‹è¯•
        test_multiple_languages()
        
        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("\nğŸ’¡ GitHub Trendingçˆ¬è™«å¯ä»¥æ­£å¸¸å·¥ä½œ")
        print("   è¿™æ˜¯ä¸€ä¸ªç›¸å¯¹å®¹æ˜“å®ç°çš„çˆ¬è™«é€‰æ‹©!")
    else:
        print("\nâŒ åŸºç¡€æµ‹è¯•å¤±è´¥")
        print("   å¯èƒ½éœ€è¦æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–GitHubé¡µé¢ç»“æ„å˜åŒ–")
