#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitHub Trending å­˜å‚¨æ¶æ„é›†æˆå™¨
å°†çˆ¬å–çš„æ•°æ®é›†æˆåˆ°arXivå¼çš„ä¸‰å±‚å­˜å‚¨æ¶æ„ä¸­
"""

import json
import os
import sys
import asyncio
import aiohttp
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

# æ·»åŠ å…±äº«æ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'shared'))
from utils import save_json


class GitHubStorageIntegrator:
    """GitHubæ•°æ®å­˜å‚¨æ¶æ„é›†æˆå™¨"""
    
    def __init__(self, base_dir: str = "crawled_data"):
        self.base_dir = Path(base_dir)
        
        # å­˜å‚¨æ¶æ„é…ç½®ï¼ˆå‚è€ƒarXivï¼‰
        self.storage_config = {
            "minio_api_url": "http://localhost:9011",
            "bucket_name": "github-trending-tools", 
            "source_id": "github_trending",
            "public_base_url": "http://60.205.160.74:9000"
        }
        
        self.upload_stats = {
            "total_files": 0,
            "success_uploads": 0,
            "failed_uploads": 0,
            "start_time": None
        }
        
        print("ğŸ”— GitHubå­˜å‚¨é›†æˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ğŸ“ æ•°æ®ç›®å½•: {self.base_dir}")
        print(f"   â˜ï¸ MinIO API: {self.storage_config['minio_api_url']}")
        print(f"   ğŸ—„ï¸ å­˜å‚¨æ¡¶: {self.storage_config['bucket_name']}")
    
    async def upload_all_tools(self) -> Dict:
        """ä¸Šä¼ æ‰€æœ‰å·¥å…·åˆ°å­˜å‚¨æ¶æ„"""
        self.upload_stats["start_time"] = datetime.now()
        
        print("\nğŸš€ å¼€å§‹ä¸Šä¼ GitHub Trendingå·¥å…·åˆ°å­˜å‚¨æ¶æ„...")
        print("=" * 60)
        
        # æŸ¥æ‰¾æ‰€æœ‰å·¥å…·ç›®å½•
        tools_dirs = []
        tools_base = self.base_dir / "tools"
        
        if tools_base.exists():
            for time_range in ["daily", "weekly", "monthly"]:
                time_dir = tools_base / time_range
                if time_dir.exists():
                    for tool_dir in time_dir.iterdir():
                        if tool_dir.is_dir():
                            tools_dirs.append((tool_dir, time_range))
        
        print(f"ğŸ“Š å‘ç° {len(tools_dirs)} ä¸ªå·¥å…·ç›®å½•")
        
        if not tools_dirs:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å·¥å…·ç›®å½•ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«")
            return self.upload_stats
        
        # æ‰¹é‡ä¸Šä¼ 
        batch_size = 5  # å¹¶å‘ä¸Šä¼ æ•°é‡
        for i in range(0, len(tools_dirs), batch_size):
            batch = tools_dirs[i:i + batch_size]
            
            print(f"\nğŸ“¦ ä¸Šä¼ æ‰¹æ¬¡ {i//batch_size + 1}: {len(batch)} ä¸ªå·¥å…·")
            
            # å¹¶å‘ä¸Šä¼ è¿™ä¸€æ‰¹
            tasks = []
            for tool_dir, time_range in batch:
                task = self.upload_single_tool(tool_dir, time_range)
                tasks.append(task)
            
            # ç­‰å¾…è¿™ä¸€æ‰¹å®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ç»Ÿè®¡ç»“æœ
            for result in results:
                if isinstance(result, Exception):
                    self.upload_stats["failed_uploads"] += 1
                    print(f"  âŒ ä¸Šä¼ å¼‚å¸¸: {result}")
                elif result:
                    self.upload_stats["success_uploads"] += 1
                else:
                    self.upload_stats["failed_uploads"] += 1
        
        # ç”Ÿæˆä¸Šä¼ æŠ¥å‘Š
        await self.generate_upload_report()
        
        return self.upload_stats
    
    async def upload_single_tool(self, tool_dir: Path, time_range: str) -> bool:
        """ä¸Šä¼ å•ä¸ªå·¥å…·åˆ°å­˜å‚¨æ¶æ„"""
        try:
            # æ£€æŸ¥æ–‡ä»¶
            content_file = tool_dir / "content.md"
            metadata_file = tool_dir / "metadata.json"
            
            if not content_file.exists():
                print(f"  âš ï¸ ç¼ºå°‘content.md: {tool_dir.name}")
                return False
            
            # è¯»å–å…ƒæ•°æ®
            metadata = {}
            if metadata_file.exists():
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                except Exception as e:
                    print(f"  âš ï¸ è¯»å–å…ƒæ•°æ®å¤±è´¥: {tool_dir.name} - {e}")
            
            # å‡†å¤‡ä¸Šä¼ æ•°æ®
            upload_metadata = {
                "title": metadata.get("name", tool_dir.name),
                "description": metadata.get("description", ""),
                "source": "github_trending",
                "category": f"github_{time_range}",
                "language": metadata.get("language", ""),
                "stars": metadata.get("stars", 0),
                "quality_score": metadata.get("quality_score", 0),
                "time_range": time_range,
                "github_url": metadata.get("url", ""),
                "topics": metadata.get("topics", []),
                "crawl_timestamp": metadata.get("crawl_timestamp", ""),
                "license": metadata.get("license", ""),
                "repo_id": metadata.get("id", tool_dir.name)
            }
            
            # ä¸Šä¼ åˆ°MinIO
            success = await self._upload_file_to_minio(
                content_file, 
                upload_metadata,
                tool_dir.name
            )
            
            if success:
                print(f"  âœ… ä¸Šä¼ æˆåŠŸ: {tool_dir.name}")
                self.upload_stats["total_files"] += 1
                return True
            else:
                print(f"  âŒ ä¸Šä¼ å¤±è´¥: {tool_dir.name}")
                return False
                
        except Exception as e:
            print(f"  âŒ ä¸Šä¼ å¼‚å¸¸: {tool_dir.name} - {e}")
            return False
    
    async def _upload_file_to_minio(self, file_path: Path, metadata: Dict, tool_name: str) -> bool:
        """ä¸Šä¼ æ–‡ä»¶åˆ°MinIOå¯¹è±¡å­˜å‚¨"""
        upload_url = f"{self.storage_config['minio_api_url']}/api/v1/files/upload"
        
        try:
            async with aiohttp.ClientSession() as session:
                # å‡†å¤‡ä¸Šä¼ æ•°æ®
                with open(file_path, 'rb') as f:
                    form_data = aiohttp.FormData()
                    form_data.add_field('file', f, filename='content.md')
                    form_data.add_field('bucket', self.storage_config['bucket_name'])
                    form_data.add_field('source_id', self.storage_config['source_id'])
                    form_data.add_field('metadata', json.dumps(metadata))
                    form_data.add_field('object_name', f"github_tools/{tool_name}/content.md")
                    
                    async with session.post(upload_url, data=form_data) as response:
                        if response.status == 200:
                            result = await response.json()
                            return result.get("success", False)
                        else:
                            error_text = await response.text()
                            print(f"    âŒ HTTPé”™è¯¯ {response.status}: {error_text[:100]}")
                            return False
                            
        except Exception as e:
            print(f"    âŒ ä¸Šä¼ å¼‚å¸¸: {e}")
            return False
    
    async def generate_upload_report(self):
        """ç”Ÿæˆä¸Šä¼ æŠ¥å‘Š"""
        end_time = datetime.now()
        duration = end_time - self.upload_stats["start_time"]
        
        total = self.upload_stats["total_files"]
        success = self.upload_stats["success_uploads"] 
        failed = self.upload_stats["failed_uploads"]
        success_rate = (success / total * 100) if total > 0 else 0
        
        report = f"""# GitHub Trending å­˜å‚¨ä¸Šä¼ æŠ¥å‘Š

## ğŸ“Š ä¸Šä¼ ç»Ÿè®¡
- **ä¸Šä¼ æ—¶é—´**: {self.upload_stats["start_time"].strftime('%Y-%m-%d %H:%M:%S')}
- **å®Œæˆæ—¶é—´**: {end_time.strftime('%Y-%m-%d %H:%M:%S')}
- **æ€»è€—æ—¶**: {duration}
- **æ–‡ä»¶æ€»æ•°**: {total}
- **æˆåŠŸä¸Šä¼ **: {success}
- **å¤±è´¥ä¸Šä¼ **: {failed}
- **æˆåŠŸç‡**: {success_rate:.1f}%

## ğŸ—ï¸ å­˜å‚¨æ¶æ„ä¿¡æ¯
- **å­˜å‚¨æ¡¶**: {self.storage_config['bucket_name']}
- **MinIOåœ°å€**: {self.storage_config['public_base_url']}
- **APIåœ°å€**: {self.storage_config['minio_api_url']}
- **æ•°æ®æºID**: {self.storage_config['source_id']}

## ğŸ“ æ•°æ®ç»„ç»‡ç»“æ„
```
MinIOå­˜å‚¨æ¡¶: {self.storage_config['bucket_name']}
â”œâ”€â”€ github_tools/
â”‚   â”œâ”€â”€ [tool_name_1]/
â”‚   â”‚   â””â”€â”€ content.md
â”‚   â”œâ”€â”€ [tool_name_2]/
â”‚   â”‚   â””â”€â”€ content.md
â”‚   â””â”€â”€ ...
```

## ğŸ” æ•°æ®è®¿é—®æ–¹å¼

### 1. é€šè¿‡MinIOè¿æ¥å™¨APIæœç´¢
```bash
# æœç´¢GitHubå·¥å…·
curl "http://localhost:9011/api/v1/elasticsearch/search?index=minio_articles&query=github_trending&size=10"

# æœç´¢ç‰¹å®šè¯­è¨€çš„å·¥å…·
curl "http://localhost:9011/api/v1/elasticsearch/search?index=minio_articles&query=python&size=10"
```

### 2. ç›´æ¥MinIOå¯¹è±¡è®¿é—®
```bash
# è®¿é—®å…·ä½“å·¥å…·å†…å®¹
{self.storage_config['public_base_url']}/{self.storage_config['bucket_name']}/github_tools/[tool_name]/content.md
```

## ğŸ“ˆ æ•°æ®è´¨é‡
- æ‰€æœ‰ä¸Šä¼ çš„å·¥å…·éƒ½ç»è¿‡AIç›¸å…³æ€§éªŒè¯
- åŒ…å«å®Œæ•´çš„GitHubå…ƒæ•°æ®ä¿¡æ¯
- æ”¯æŒå…¨æ–‡æ£€ç´¢å’Œè¯­ä¹‰æœç´¢
- è‡ªåŠ¨å»é‡ï¼Œé¿å…é‡å¤æ•°æ®

## ğŸ”„ é›†æˆçŠ¶æ€
- âœ… MinIOå¯¹è±¡å­˜å‚¨: æ–‡ä»¶å­˜å‚¨å®Œæˆ
- âœ… PostgreSQL: å…ƒæ•°æ®è®°å½•å®Œæˆ  
- âœ… Elasticsearch: å…¨æ–‡ç´¢å¼•å»ºç«‹
- âœ… APIæ¥å£: æ”¯æŒæœç´¢å’Œè®¿é—®
"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.base_dir / f"upload_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("\n" + "=" * 60)
        print("ğŸ“‹ ä¸Šä¼ å®ŒæˆæŠ¥å‘Š:")
        print(f"   â±ï¸ æ€»è€—æ—¶: {duration}")
        print(f"   ğŸ“Š æˆåŠŸç‡: {success_rate:.1f}% ({success}/{total})")
        print(f"   ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {report_file}")
        print(f"\nğŸ” æ•°æ®æŸ¥çœ‹:")
        print(f"   MinIOåœ°å€: {self.storage_config['public_base_url']}")
        print(f"   æœç´¢API: {self.storage_config['minio_api_url']}/api/v1/elasticsearch/search")
    
    async def check_storage_connection(self) -> bool:
        """æ£€æŸ¥å­˜å‚¨æ¶æ„è¿æ¥çŠ¶æ€"""
        print("ğŸ”§ æ£€æŸ¥å­˜å‚¨æ¶æ„è¿æ¥çŠ¶æ€...")
        
        try:
            # æ£€æŸ¥MinIOè¿æ¥å™¨API
            async with aiohttp.ClientSession() as session:
                check_url = f"{self.storage_config['minio_api_url']}/api/v1/buckets"
                
                async with session.get(check_url) as response:
                    if response.status == 200:
                        buckets = await response.json()
                        print(f"  âœ… MinIOè¿æ¥å™¨: æ­£å¸¸ (å‘ç° {len(buckets)} ä¸ªå­˜å‚¨æ¡¶)")
                        
                        # æ£€æŸ¥ç›®æ ‡å­˜å‚¨æ¡¶æ˜¯å¦å­˜åœ¨
                        bucket_names = [b.get('name', '') for b in buckets]
                        if self.storage_config['bucket_name'] in bucket_names:
                            print(f"  âœ… ç›®æ ‡å­˜å‚¨æ¡¶ '{self.storage_config['bucket_name']}': å·²å­˜åœ¨")
                        else:
                            print(f"  âš ï¸ ç›®æ ‡å­˜å‚¨æ¡¶ '{self.storage_config['bucket_name']}': ä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨åˆ›å»º")
                        
                        return True
                    else:
                        print(f"  âŒ MinIOè¿æ¥å™¨: è¿æ¥å¤±è´¥ ({response.status})")
                        return False
                        
        except Exception as e:
            print(f"  âŒ å­˜å‚¨æ¶æ„è¿æ¥æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def show_integration_guide(self):
        """æ˜¾ç¤ºé›†æˆæŒ‡å—"""
        print("""
ğŸ”— GitHub Trending å­˜å‚¨æ¶æ„é›†æˆæŒ‡å—
================================

ğŸ“‹ å‰ç½®æ¡ä»¶:
  1. MinIOæœåŠ¡è¿è¡Œåœ¨ 60.205.160.74:9000
  2. PostgreSQLæœåŠ¡è¿è¡Œåœ¨ 60.205.160.74:5432  
  3. ElasticsearchæœåŠ¡è¿è¡Œåœ¨ 60.205.160.74:9200
  4. MinIOè¿æ¥å™¨è¿è¡Œåœ¨ localhost:9011

ğŸš€ å¯åŠ¨MinIOè¿æ¥å™¨:
  cd ../../m1n10C0nnect0r/minio-file-manager/backend
  python run.py

ğŸ“¤ ä¸Šä¼ æ•°æ®åˆ°å­˜å‚¨æ¶æ„:
  python storage_integrator.py --upload

ğŸ” æ£€æŸ¥è¿æ¥çŠ¶æ€:
  python storage_integrator.py --check

ğŸ“Š æŸ¥çœ‹ä¸Šä¼ æŠ¥å‘Š:
  python storage_integrator.py --report

ğŸ’¡ é›†æˆåå¯ä»¥äº«å—:
  âœ… äº‘ç«¯å­˜å‚¨: MinIOå¯¹è±¡å­˜å‚¨
  âœ… å…ƒæ•°æ®ç®¡ç†: PostgreSQLå…³ç³»æ•°æ®åº“
  âœ… å…¨æ–‡æ£€ç´¢: Elasticsearchæœç´¢å¼•æ“
  âœ… APIæ¥å£: ç»Ÿä¸€çš„æ•°æ®è®¿é—®æ¥å£
  âœ… æ•°æ®æŒä¹…åŒ–: å¯é çš„æ•°æ®å¤‡ä»½æœºåˆ¶
        """)


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="GitHub Trending å­˜å‚¨æ¶æ„é›†æˆå™¨")
    parser.add_argument('--upload', action='store_true', help='ä¸Šä¼ æ•°æ®åˆ°å­˜å‚¨æ¶æ„')
    parser.add_argument('--check', action='store_true', help='æ£€æŸ¥å­˜å‚¨è¿æ¥çŠ¶æ€')
    parser.add_argument('--report', action='store_true', help='æ˜¾ç¤ºé›†æˆæŒ‡å—')
    parser.add_argument('--data-dir', default='crawled_data', help='æ•°æ®ç›®å½•')
    
    args = parser.parse_args()
    
    integrator = GitHubStorageIntegrator(args.data_dir)
    
    if args.check:
        await integrator.check_storage_connection()
    elif args.upload:
        # å…ˆæ£€æŸ¥è¿æ¥
        if await integrator.check_storage_connection():
            await integrator.upload_all_tools()
        else:
            print("âŒ å­˜å‚¨æ¶æ„è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€")
    elif args.report:
        integrator.show_integration_guide()
    else:
        # é»˜è®¤æ˜¾ç¤ºæŒ‡å—
        integrator.show_integration_guide()


if __name__ == "__main__":
    asyncio.run(main())
